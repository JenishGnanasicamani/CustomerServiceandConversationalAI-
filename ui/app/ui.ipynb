{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "from datetime import datetime, timedelta\n",
        "from pymongo import MongoClient\n",
        "import json"
      ],
      "metadata": {
        "id": "SCcG9hFiZXTv"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# MongoDB CONNECTION\n",
        "# -------------------------\n",
        "MONGO_URI = \"mongodb+srv://cia_db_user:qG5hStEqWkvAHrVJ@capstone-project.yyfpvqh.mongodb.net/?retryWrites=true&w=majority&appName=CAPSTONE-PROJECT\"\n",
        "DATABASE_NAME = \"csai\"\n",
        "COLLECTION_NAME = \"agentic_analysis\"\n"
      ],
      "metadata": {
        "id": "V9ZCfJdQZZYH"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_mongo(uri=MONGO_URI, db_name=DATABASE_NAME, collection_name=COLLECTION_NAME):\n",
        "    \"\"\"Connect to MongoDB and read data from collection\"\"\"\n",
        "    try:\n",
        "        client = MongoClient(uri)\n",
        "        db = client[db_name]\n",
        "        collection = db[collection_name]\n",
        "        data = list(collection.find())\n",
        "        for doc in data:\n",
        "            doc.pop(\"_id\", None)\n",
        "        # Convert datetime fields safely\n",
        "        for doc in data:\n",
        "            for k, v in doc.items():\n",
        "                if isinstance(v, datetime):\n",
        "                    doc[k] = v.isoformat()\n",
        "        print(f\"✅ Loaded {len(data)} records from MongoDB.\")\n",
        "        return {\"selected_records\": data}  # maintain JSON-like structure\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error connecting to MongoDB: {e}\")\n",
        "        return {\"selected_records\": []}\n",
        "\n"
      ],
      "metadata": {
        "id": "Dx8nMS6mZcxw"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global MongoDB data\n",
        "data = load_data_from_mongo()\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpIO_K2HawAX",
        "outputId": "a84afdcb-3631-4f43-9787-bea8862ceb92"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 5 records from MongoDB.\n",
            "{'selected_records': [{'conversation_id': 3751, 'customer': 'Delta', 'created_at': '2025-10-05T22:04:45.771850', 'created_time': '22:04:45', 'conversation_summary': {'total_messages': 2, 'customer_messages': 1, 'agent_messages': 1, 'conversation_type': 'Complaint about airline staff behavior', 'intent': 'Complaint', 'topic': 'Technical Support', 'final_sentiment': 'Negative', 'categorization': 'Complaint about airline staff behavior'}, 'performance_metrics': {'categories': {'accuracy_compliance': {'category_description': 'Measures Accuracy Compliance performance', 'overall_score': 6.0, 'kpis': {'resolution_completeness': {'score': 6.0, 'reason': \"The 2-message conversation about Technical Support followed a standard support pattern. While resolution steps may have been taken, the conversation format didn't capture detailed problem-solving documentation or explicit resolution confirmation statements.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - resolves most customer issues effectively', 'sub_kpis': {'issue_identification': {'score': 6.167928121165979, 'reason': 'Agent addressed the customer inquiry systematically. Problem recognition was handled through standard inquiry process'}, 'solution_depth': {'score': 6.7474927193653995, 'reason': 'Agent provided standard solution approach. Solution included basic resolution steps'}, 'follow_up_clarity': {'score': 5.850854714993835, 'reason': 'Agent completed resolution without explicit follow-up offer. Timeline communication was general'}, 'confirmation_process': {'score': 5.936809639286709, 'reason': 'Resolution confirmation was handled through standard completion process. Customer satisfaction was implied through interaction completion'}}, 'overall_score': 6.0}, 'accuracy_automated_responses': {'score': 6.0, 'reason': \"Information exchange in this Technical Support interaction was straightforward. Technical accuracy assessment requires specific factual claims or instructions that weren't prominently featured in this particular conversation format.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains good accuracy standards'}}}, 'empathy_communication': {'category_description': 'Measures Empathy Communication performance', 'overall_score': 6.12, 'kpis': {'empathy_score': {'score': 6.06, 'reason': \"Analysis of Empathy Score reveals specific evidence from the conversation. Customer responses provide evidence of the agent's performance in this area. Key evidence includes: relevant interaction ('@Delta, normally I love flying with you, but I’m e...'). The score of 6.5 indicates good performance with clear evidence supporting this assessment. Overall score calculated using weighted formula: 6.06\", 'evidence': [], 'normalized_score': 0.65, 'confidence': 0.9, 'interpretation': 'good - shows adequate emotional awareness', 'sub_kpis': {'emotion_recognition': {'score': 5.32, 'reason': 'Sub-factor analysis for Emotion Recognition based on conversation evidence', 'evidence': ['Customer: \"@Delta, normally I love flying with you, but I’m extremely upset at how your team acted tonight. A team-member unapologetically snatched my bag out of my hands after I was told to wait to see if there was space overhead. There was. I said no and I feel violated. I’m not alone.\"'], 'normalized_score': 0.532, 'confidence': 0.75, 'interpretation': 'satisfactory'}, 'acknowledgment_feelings': {'score': 6.61, 'reason': 'Sub-factor analysis for Acknowledgment of Feelings based on conversation evidence', 'evidence': [], 'normalized_score': 0.661, 'confidence': 0.65, 'interpretation': 'good'}, 'appropriate_response': {'score': 6.7, 'reason': 'Sub-factor analysis for Appropriate Response based on conversation evidence', 'evidence': [], 'normalized_score': 0.67, 'confidence': 0.6, 'interpretation': 'good'}, 'personalization': {'score': 5.0, 'reason': 'Sub-factor analysis for Personalization based on conversation evidence', 'evidence': [], 'normalized_score': 1.0, 'confidence': 0.6, 'interpretation': 'needs improvement'}, 'supportive_language': {'score': 5.85, 'reason': 'Sub-factor analysis for Supportive Language based on conversation evidence', 'evidence': [], 'normalized_score': 0.585, 'confidence': 0.6, 'interpretation': 'satisfactory - communication clarity needs improvement'}, 'active_listening': {'score': 7.03, 'reason': 'Sub-factor analysis for Active Listening Indicators based on conversation evidence', 'evidence': [], 'normalized_score': 0.703, 'confidence': 0.65, 'interpretation': 'very good'}}, 'overall_score': 6.06}, 'sentiment_shift': {'score': 6.5, 'reason': \"Analysis of Sentiment Shift reveals specific evidence from the conversation. Customer responses provide evidence of the agent's performance in this area. Key evidence includes: relevant interaction ('@Delta, normally I love flying with you, but I’m e...'). The score of 6.5 indicates good performance with clear evidence supporting this assessment.\", 'evidence': [], 'normalized_score': 0.65, 'confidence': 0.9, 'interpretation': 'good - maintains positive interaction tone'}, 'clarity_language': {'score': 6.19, 'reason': \"Agent responses averaged 0 words per message in this Technical Support discussion. Communication was functional though didn't showcase specific clarity enhancement techniques or customer comprehension confirmations. Overall score calculated using weighted formula: 6.19\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains clear communication standards', 'sub_kpis': {'readability_level': {'score': 6.08, 'reason': 'Sub-factor analysis for Readability Level based on conversation evidence', 'evidence': [], 'normalized_score': 0.608, 'confidence': 0.6, 'interpretation': 'good'}, 'jargon_usage': {'score': 6.45, 'reason': 'Sub-factor analysis for Jargon Usage based on conversation evidence', 'evidence': [], 'normalized_score': 0.645, 'confidence': 0.6, 'interpretation': 'good'}, 'sentence_structure': {'score': 6.81, 'reason': 'Sub-factor analysis for Sentence Structure based on conversation evidence', 'evidence': [], 'normalized_score': 0.681, 'confidence': 0.6, 'interpretation': 'good'}, 'coherence': {'score': 6.65, 'reason': 'Sub-factor analysis for Coherence based on conversation evidence', 'evidence': [], 'normalized_score': 0.665, 'confidence': 0.6, 'interpretation': 'good'}, 'active_voice': {'score': 5.8, 'reason': 'Sub-factor analysis for Use of Active Voice based on conversation evidence', 'evidence': [], 'normalized_score': 0.58, 'confidence': 0.6, 'interpretation': 'satisfactory'}, 'conciseness': {'score': 5.16, 'reason': 'Sub-factor analysis for Conciseness based on conversation evidence', 'evidence': [], 'normalized_score': 0.516, 'confidence': 0.6, 'interpretation': 'satisfactory'}}, 'overall_score': 6.19}, 'cultural_sensitivity': {'score': 6.0, 'reason': 'This 2-message Technical Support interaction proceeded through standard professional channels. No cultural considerations, accommodations, or sensitivity requirements emerged that would demonstrate cultural awareness capabilities.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - shows appropriate cultural sensitivity'}, 'adaptability_quotient': {'score': 6.0, 'reason': 'Agent responses in this Technical Support case followed consistent approach patterns. No specific customer preference adjustments, communication style modifications, or adaptive problem-solving variations were required or demonstrated.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - adapts well to customer needs'}, 'conversation_flow': {'score': 6.0, 'reason': 'The 2-message exchange about Technical Support maintained basic turn-taking structure. Standard greeting-issue-response-closure pattern without notable flow disruptions or enhancement techniques.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.7, 'interpretation': 'good'}}}, 'efficiency_resolution': {'category_description': 'Measures Efficiency Resolution performance', 'overall_score': 6.0, 'kpis': {'followup_necessity': {'score': 6.0, 'reason': 'Customer engagement in this 2-message Technical Support interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good'}, 'customer_effort_score': {'score': 6.0, 'reason': 'Customer engagement in this 2-message Technical Support interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - demonstrates good efficiency practices', 'sub_kpis': {'information_gathering': {'score': 5.545742690040624, 'reason': 'Agent gathered necessary information through standard process. Information collection was streamlined and secure'}, 'process_simplification': {'score': 7.111708418871664, 'reason': 'Agent provided standard process guidance. Customer appreciated the resolution method'}, 'proactive_assistance': {'score': 7.120407849568385, 'reason': 'Agent responded to customer requests as presented. Proactive elements included acknowledging frustration and offering immediate alternative solution'}}, 'overall_score': 6.0}, 'first_response_accuracy': {'score': 6.0, 'reason': \"Information exchange in this Technical Support interaction was straightforward. Technical accuracy assessment requires specific factual claims or instructions that weren't prominently featured in this particular conversation format.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains good accuracy standards'}, 'csat_resolution': {'score': 6.0, 'reason': \"The 2-message conversation about Technical Support followed a standard support pattern. While resolution steps may have been taken, the conversation format didn't capture detailed problem-solving documentation or explicit resolution confirmation statements.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - resolves most customer issues effectively'}, 'escalation_rate': {'score': 6.0, 'reason': 'This Technical Support interaction remained at initial support level throughout 2 messages. No escalation triggers, complexity increases, or elevated support requirements emerged during the conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good'}, 'customer_effort_reduction': {'score': 6.0, 'reason': 'Customer engagement in this 2-message Technical Support interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - demonstrates good efficiency practices'}}}}}, 'analysis_timestamp': '2025-10-05T22:05:31.821329', 'analysis_method': 'LLM-based Agent Analysis', 'model_used': 'claude-4', 'agent_output': 'I\\'ll perform a complete and systematic analysis of the provided conversation data against all configured KPIs. Let me start by formatting the conversation and then analyzing each KPI systematically.\\n\\n<invoke name=\"conversation_formatter_tool\">\\n<parameter name=\"conversation_data\">{\"tweets\": [{\"tweet_id\": 470334, \"author_id\": \"226977\", \"role\": \"Customer\", \"inbound\": true, \"created_at\": \"2024-12-01\", \"text\": \"@Delta, normally I love flying with you, but I\\'m extremely upset at how your team acted tonight. A team-member unapologetically snatched my bag out of my hands after I was told to wait to see if there was space overhead. There was. I said no and I feel violated. I\\'m not alone.\"}, {\"tweet_id\": 470333, \"author_id\": \"Delta\", \"role\": \"Service Provider\", \"inbound\": false, \"created_at\": \"2024-12-01\", \"text\": \"@226977 ...appropriate desk for review.  *HSD 2/2\"}], \"classification\": {\"categorization\": \"Complaint about airline staff behavior\", \"intent\": \"Complaint\", \"topic\": \"Technical Support...', 'source_object_id': '68dce4d8b1dee7d0fab60b02', 'source_timestamp': '2025-10-05T22:05:31.821000', 'analysis_metadata': {'processed_timestamp': datetime.datetime(2025, 10, 5, 22, 5, 31, 821000), 'source_collection': 'sentiment_analysis', 'analysis_version': '4.2.0', 'model_used': 'claude-4', 'restructured_format': True}, 'persistence_metadata': {'inserted_timestamp': datetime.datetime(2025, 10, 5, 22, 5, 31, 821000), 'collection': 'agentic_analysis', 'job_name': 'conversation_performance_analysis', 'storage_type': 'mongodb'}}, {'conversation_id': 4485, 'customer': 'Delta', 'created_at': '2025-10-05T22:05:31.961544', 'created_time': '22:05:31', 'conversation_summary': {'total_messages': 3, 'customer_messages': 2, 'agent_messages': 1, 'conversation_type': 'Complaint about customer service', 'intent': 'Technical Support', 'topic': 'General', 'final_sentiment': 'Negative', 'categorization': 'Complaint about customer service'}, 'performance_metrics': {'categories': {'accuracy_compliance': {'category_description': 'Measures Accuracy Compliance performance', 'overall_score': 6.0, 'kpis': {'resolution_completeness': {'score': 6.0, 'reason': \"The 3-message conversation about General followed a standard support pattern. While resolution steps may have been taken, the conversation format didn't capture detailed problem-solving documentation or explicit resolution confirmation statements.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - resolves most customer issues effectively', 'sub_kpis': {'issue_identification': {'score': 6.167928121165979, 'reason': 'Agent addressed the customer inquiry systematically. Problem recognition was handled through standard inquiry process'}, 'solution_depth': {'score': 6.7474927193653995, 'reason': 'Agent provided standard solution approach. Solution included basic resolution steps'}, 'follow_up_clarity': {'score': 5.850854714993835, 'reason': 'Agent completed resolution without explicit follow-up offer. Timeline communication was general'}, 'confirmation_process': {'score': 5.936809639286709, 'reason': 'Resolution confirmation was handled through standard completion process. Customer satisfaction was implied through interaction completion'}}, 'overall_score': 6.0}, 'accuracy_automated_responses': {'score': 6.0, 'reason': \"Information exchange in this General interaction was straightforward. Technical accuracy assessment requires specific factual claims or instructions that weren't prominently featured in this particular conversation format.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains good accuracy standards'}}}, 'empathy_communication': {'category_description': 'Measures Empathy Communication performance', 'overall_score': 6.21, 'kpis': {'empathy_score': {'score': 6.06, 'reason': \"Analysis of Empathy Score reveals specific evidence from the conversation. Key evidence includes: relevant interaction ('@253716 I do apologize for the long hold times we'...'). The score of 6.5 indicates good performance with clear evidence supporting this assessment. Overall score calculated using weighted formula: 6.06\", 'evidence': [], 'normalized_score': 0.65, 'confidence': 0.9, 'interpretation': 'good - shows adequate emotional awareness', 'sub_kpis': {'emotion_recognition': {'score': 5.32, 'reason': 'Sub-factor analysis for Emotion Recognition based on conversation evidence', 'evidence': [], 'normalized_score': 0.532, 'confidence': 0.6, 'interpretation': 'satisfactory'}, 'acknowledgment_feelings': {'score': 6.61, 'reason': 'Sub-factor analysis for Acknowledgment of Feelings based on conversation evidence', 'evidence': [], 'normalized_score': 0.661, 'confidence': 0.65, 'interpretation': 'good'}, 'appropriate_response': {'score': 6.7, 'reason': 'Sub-factor analysis for Appropriate Response based on conversation evidence', 'evidence': [], 'normalized_score': 0.67, 'confidence': 0.6, 'interpretation': 'good'}, 'personalization': {'score': 5.0, 'reason': 'Sub-factor analysis for Personalization based on conversation evidence', 'evidence': [], 'normalized_score': 1.0, 'confidence': 0.6, 'interpretation': 'needs improvement'}, 'supportive_language': {'score': 5.85, 'reason': 'Sub-factor analysis for Supportive Language based on conversation evidence', 'evidence': [], 'normalized_score': 0.585, 'confidence': 0.6, 'interpretation': 'satisfactory - communication clarity needs improvement'}, 'active_listening': {'score': 7.03, 'reason': 'Sub-factor analysis for Active Listening Indicators based on conversation evidence', 'evidence': [], 'normalized_score': 0.703, 'confidence': 0.65, 'interpretation': 'very good'}}, 'overall_score': 6.06}, 'sentiment_shift': {'score': 6.0, 'reason': \"Customer tone remained relatively consistent from initial contact ('@Delta seriously? a two hour h...') through conclusion ('@Delta @253716 Hey you got any...'). No dramatic sentiment transformation indicators were present in this General interaction.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains positive interaction tone'}, 'clarity_language': {'score': 6.19, 'reason': \"Agent responses averaged 0 words per message in this General discussion. Communication was functional though didn't showcase specific clarity enhancement techniques or customer comprehension confirmations. Overall score calculated using weighted formula: 6.19\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains clear communication standards', 'sub_kpis': {'readability_level': {'score': 6.08, 'reason': 'Sub-factor analysis for Readability Level based on conversation evidence', 'evidence': [], 'normalized_score': 0.608, 'confidence': 0.6, 'interpretation': 'good'}, 'jargon_usage': {'score': 6.45, 'reason': 'Sub-factor analysis for Jargon Usage based on conversation evidence', 'evidence': [], 'normalized_score': 0.645, 'confidence': 0.6, 'interpretation': 'good'}, 'sentence_structure': {'score': 6.81, 'reason': 'Sub-factor analysis for Sentence Structure based on conversation evidence', 'evidence': [], 'normalized_score': 0.681, 'confidence': 0.6, 'interpretation': 'good'}, 'coherence': {'score': 6.65, 'reason': 'Sub-factor analysis for Coherence based on conversation evidence', 'evidence': [], 'normalized_score': 0.665, 'confidence': 0.6, 'interpretation': 'good'}, 'active_voice': {'score': 5.8, 'reason': 'Sub-factor analysis for Use of Active Voice based on conversation evidence', 'evidence': [], 'normalized_score': 0.58, 'confidence': 0.6, 'interpretation': 'satisfactory'}, 'conciseness': {'score': 5.16, 'reason': 'Sub-factor analysis for Conciseness based on conversation evidence', 'evidence': [], 'normalized_score': 0.516, 'confidence': 0.6, 'interpretation': 'satisfactory'}}, 'overall_score': 6.19}, 'cultural_sensitivity': {'score': 6.0, 'reason': 'This 3-message General interaction proceeded through standard professional channels. No cultural considerations, accommodations, or sensitivity requirements emerged that would demonstrate cultural awareness capabilities.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - shows appropriate cultural sensitivity'}, 'adaptability_quotient': {'score': 6.0, 'reason': 'Agent responses in this General case followed consistent approach patterns. No specific customer preference adjustments, communication style modifications, or adaptive problem-solving variations were required or demonstrated.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - adapts well to customer needs'}, 'conversation_flow': {'score': 7.0, 'reason': \"Analysis of Conversation Flow reveals specific evidence from the conversation. Customer responses provide evidence of the agent's performance in this area. Key evidence includes: relevant interaction ('@253716 I do apologize for the long hold times we'...'); relevant interaction ('@Delta @253716 Hey you got any weed man...'). The score of 7.0 indicates good performance with clear evidence supporting this assessment.\", 'evidence': [], 'normalized_score': 0.7, 'confidence': 0.95, 'interpretation': 'very good'}}}, 'efficiency_resolution': {'category_description': 'Measures Efficiency Resolution performance', 'overall_score': 6.0, 'kpis': {'followup_necessity': {'score': 6.0, 'reason': 'Customer engagement in this 3-message General interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good'}, 'customer_effort_score': {'score': 6.0, 'reason': 'Customer engagement in this 3-message General interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - demonstrates good efficiency practices', 'sub_kpis': {'information_gathering': {'score': 5.545742690040624, 'reason': 'Agent gathered necessary information through standard process. Information collection was streamlined and secure'}, 'process_simplification': {'score': 7.111708418871664, 'reason': 'Agent provided standard process guidance. Customer appreciated the resolution method'}, 'proactive_assistance': {'score': 7.120407849568385, 'reason': 'Agent responded to customer requests as presented. Proactive elements included acknowledging frustration and offering immediate alternative solution'}}, 'overall_score': 6.0}, 'first_response_accuracy': {'score': 6.0, 'reason': \"Information exchange in this General interaction was straightforward. Technical accuracy assessment requires specific factual claims or instructions that weren't prominently featured in this particular conversation format.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains good accuracy standards'}, 'csat_resolution': {'score': 6.0, 'reason': \"The 3-message conversation about General followed a standard support pattern. While resolution steps may have been taken, the conversation format didn't capture detailed problem-solving documentation or explicit resolution confirmation statements.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - resolves most customer issues effectively'}, 'escalation_rate': {'score': 6.0, 'reason': 'This General interaction remained at initial support level throughout 3 messages. No escalation triggers, complexity increases, or elevated support requirements emerged during the conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.7, 'interpretation': 'good'}, 'customer_effort_reduction': {'score': 6.0, 'reason': 'Customer engagement in this 3-message General interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - demonstrates good efficiency practices'}}}}}, 'analysis_timestamp': '2025-10-05T22:06:19.808457', 'analysis_method': 'LLM-based Agent Analysis', 'model_used': 'claude-4', 'agent_output': 'I\\'ll perform a complete and systematic analysis of the provided conversation data against all configured KPIs. Let me start by formatting the conversation and then analyzing each KPI systematically.\\n\\n<invoke name=\"conversation_formatter_tool\">\\n<parameter name=\"conversation_data\">{\"tweets\": [{\"tweet_id\": 569704, \"author_id\": \"253716\", \"role\": \"Customer\", \"inbound\": true, \"created_at\": \"2024-12-03\", \"text\": \"@Delta seriously? a two hour hold time?? what happened to your call back service? #igotalifetolive\"}, {\"tweet_id\": 569701, \"author_id\": \"Delta\", \"role\": \"Service Provider\", \"inbound\": false, \"created_at\": \"2024-12-03\", \"text\": \"@253716 I do apologize for the long hold times we\\'re experiencing tonight. How may we help you via this channel? *TAC\"}, {\"tweet_id\": 569702, \"author_id\": \"116808\", \"role\": \"Customer\", \"inbound\": true, \"created_at\": \"2024-12-03\", \"text\": \"@Delta @253716 Hey you got any weed man\"}], \"classification\": {\"categorization\": \"Complaint about customer service\", \"inten...', 'source_object_id': '68dce4efb1dee7d0fab60b03', 'source_timestamp': '2025-10-05T22:06:19.808000', 'analysis_metadata': {'processed_timestamp': datetime.datetime(2025, 10, 5, 22, 6, 19, 808000), 'source_collection': 'sentiment_analysis', 'analysis_version': '4.2.0', 'model_used': 'claude-4', 'restructured_format': True}, 'persistence_metadata': {'inserted_timestamp': datetime.datetime(2025, 10, 5, 22, 6, 19, 808000), 'collection': 'agentic_analysis', 'job_name': 'conversation_performance_analysis', 'storage_type': 'mongodb'}}, {'conversation_id': 4229, 'customer': 'Delta', 'created_at': '2025-10-05T22:06:19.940847', 'created_time': '22:06:19', 'conversation_summary': {'total_messages': 4, 'customer_messages': 3, 'agent_messages': 1, 'conversation_type': 'Complaint about poor customer service', 'intent': 'Complaint', 'topic': 'Technical Support', 'final_sentiment': 'Negative', 'categorization': 'Complaint about poor customer service'}, 'performance_metrics': {'categories': {'accuracy_compliance': {'category_description': 'Measures Accuracy Compliance performance', 'overall_score': 6.0, 'kpis': {'resolution_completeness': {'score': 6.0, 'reason': \"The 4-message conversation about Technical Support followed a standard support pattern. While resolution steps may have been taken, the conversation format didn't capture detailed problem-solving documentation or explicit resolution confirmation statements.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - resolves most customer issues effectively', 'sub_kpis': {'issue_identification': {'score': 6.167928121165979, 'reason': 'Agent addressed the customer inquiry systematically. Problem recognition was handled through standard inquiry process'}, 'solution_depth': {'score': 6.7474927193653995, 'reason': 'Agent provided standard solution approach. Solution included basic resolution steps'}, 'follow_up_clarity': {'score': 5.850854714993835, 'reason': 'Agent completed resolution without explicit follow-up offer. Timeline communication was general'}, 'confirmation_process': {'score': 5.936809639286709, 'reason': 'Resolution confirmation was handled through standard completion process. Customer satisfaction was implied through interaction completion'}}, 'overall_score': 6.0}, 'accuracy_automated_responses': {'score': 6.0, 'reason': \"Information exchange in this Technical Support interaction was straightforward. Technical accuracy assessment requires specific factual claims or instructions that weren't prominently featured in this particular conversation format.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains good accuracy standards'}}}, 'empathy_communication': {'category_description': 'Measures Empathy Communication performance', 'overall_score': 6.56, 'kpis': {'empathy_score': {'score': 6.56, 'reason': \"Analysis of Empathy Score reveals specific evidence from the conversation. Key evidence includes: relevant interaction ('@243850 I am very sorry that you feel this way. We...'). The score of 7.0 indicates good performance with clear evidence supporting this assessment. Overall score calculated using weighted formula: 6.56\", 'evidence': [], 'normalized_score': 0.7, 'confidence': 0.9, 'interpretation': 'very good - shows adequate emotional awareness', 'sub_kpis': {'emotion_recognition': {'score': 5.82, 'reason': 'Sub-factor analysis for Emotion Recognition based on conversation evidence', 'evidence': [], 'normalized_score': 0.582, 'confidence': 0.6, 'interpretation': 'satisfactory'}, 'acknowledgment_feelings': {'score': 7.11, 'reason': 'Sub-factor analysis for Acknowledgment of Feelings based on conversation evidence', 'evidence': [], 'normalized_score': 0.711, 'confidence': 0.65, 'interpretation': 'very good'}, 'appropriate_response': {'score': 7.2, 'reason': 'Sub-factor analysis for Appropriate Response based on conversation evidence', 'evidence': [], 'normalized_score': 0.72, 'confidence': 0.6, 'interpretation': 'very good'}, 'personalization': {'score': 5.5, 'reason': 'Sub-factor analysis for Personalization based on conversation evidence', 'evidence': [], 'normalized_score': 0.55, 'confidence': 0.6, 'interpretation': 'satisfactory'}, 'supportive_language': {'score': 6.35, 'reason': 'Sub-factor analysis for Supportive Language based on conversation evidence', 'evidence': [], 'normalized_score': 0.635, 'confidence': 0.6, 'interpretation': 'good - maintains clear communication standards'}, 'active_listening': {'score': 7.53, 'reason': 'Sub-factor analysis for Active Listening Indicators based on conversation evidence', 'evidence': [], 'normalized_score': 0.753, 'confidence': 0.65, 'interpretation': 'very good'}}, 'overall_score': 6.56}, 'sentiment_shift': {'score': 7.3, 'reason': \"Analysis of Sentiment Shift reveals specific evidence from the conversation. Customer responses provide evidence of the agent's performance in this area. Key evidence includes: positive customer feedback ('@Delta @Delta thanks for cutting my time short wit...'). The score of 7.3 indicates good performance with clear evidence supporting this assessment.\", 'evidence': ['Customer: \"@Delta @Delta thanks for cutting my time short with my mother who I won\\'t get to see for years after I got to boot camp. This how you treat Vets? I\\'ll make that notes\"'], 'normalized_score': 0.73, 'confidence': 0.9, 'interpretation': 'very good - maintains positive interaction tone'}, 'clarity_language': {'score': 6.19, 'reason': \"Agent responses averaged 0 words per message in this Technical Support discussion. Communication was functional though didn't showcase specific clarity enhancement techniques or customer comprehension confirmations. Overall score calculated using weighted formula: 6.19\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains clear communication standards', 'sub_kpis': {'readability_level': {'score': 6.08, 'reason': 'Sub-factor analysis for Readability Level based on conversation evidence', 'evidence': [], 'normalized_score': 0.608, 'confidence': 0.6, 'interpretation': 'good'}, 'jargon_usage': {'score': 6.45, 'reason': 'Sub-factor analysis for Jargon Usage based on conversation evidence', 'evidence': [], 'normalized_score': 0.645, 'confidence': 0.6, 'interpretation': 'good'}, 'sentence_structure': {'score': 6.81, 'reason': 'Sub-factor analysis for Sentence Structure based on conversation evidence', 'evidence': [], 'normalized_score': 0.681, 'confidence': 0.6, 'interpretation': 'good'}, 'coherence': {'score': 6.65, 'reason': 'Sub-factor analysis for Coherence based on conversation evidence', 'evidence': [], 'normalized_score': 0.665, 'confidence': 0.6, 'interpretation': 'good'}, 'active_voice': {'score': 5.8, 'reason': 'Sub-factor analysis for Use of Active Voice based on conversation evidence', 'evidence': [], 'normalized_score': 0.58, 'confidence': 0.6, 'interpretation': 'satisfactory'}, 'conciseness': {'score': 5.16, 'reason': 'Sub-factor analysis for Conciseness based on conversation evidence', 'evidence': [], 'normalized_score': 0.516, 'confidence': 0.6, 'interpretation': 'satisfactory'}}, 'overall_score': 6.19}, 'cultural_sensitivity': {'score': 6.0, 'reason': 'This 4-message Technical Support interaction proceeded through standard professional channels. No cultural considerations, accommodations, or sensitivity requirements emerged that would demonstrate cultural awareness capabilities.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - shows appropriate cultural sensitivity'}, 'adaptability_quotient': {'score': 6.0, 'reason': 'Agent responses in this Technical Support case followed consistent approach patterns. No specific customer preference adjustments, communication style modifications, or adaptive problem-solving variations were required or demonstrated.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - adapts well to customer needs'}, 'conversation_flow': {'score': 7.3, 'reason': \"Analysis of Conversation Flow reveals specific evidence from the conversation. Customer responses provide evidence of the agent's performance in this area. Key evidence includes: relevant interaction ('@Delta @Delta thanks for cutting my time short wit...'); relevant interaction ('@243850 I am very sorry that you feel this way. We...'). The score of 7.3 indicates good performance with clear evidence supporting this assessment.\", 'evidence': [], 'normalized_score': 0.73, 'confidence': 0.95, 'interpretation': 'very good'}}}, 'efficiency_resolution': {'category_description': 'Measures Efficiency Resolution performance', 'overall_score': 6.0, 'kpis': {'followup_necessity': {'score': 6.0, 'reason': 'Customer engagement in this 4-message Technical Support interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good'}, 'customer_effort_score': {'score': 6.0, 'reason': 'Customer engagement in this 4-message Technical Support interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - demonstrates good efficiency practices', 'sub_kpis': {'information_gathering': {'score': 5.545742690040624, 'reason': 'Agent gathered necessary information through standard process. Information collection was streamlined and secure'}, 'process_simplification': {'score': 7.111708418871664, 'reason': 'Agent provided standard process guidance. Customer appreciated the resolution method'}, 'proactive_assistance': {'score': 7.120407849568385, 'reason': 'Agent responded to customer requests as presented. Proactive elements included acknowledging frustration and offering immediate alternative solution'}}, 'overall_score': 6.0}, 'first_response_accuracy': {'score': 6.0, 'reason': \"Information exchange in this Technical Support interaction was straightforward. Technical accuracy assessment requires specific factual claims or instructions that weren't prominently featured in this particular conversation format.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains good accuracy standards'}, 'csat_resolution': {'score': 6.0, 'reason': \"The 4-message conversation about Technical Support followed a standard support pattern. While resolution steps may have been taken, the conversation format didn't capture detailed problem-solving documentation or explicit resolution confirmation statements.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - resolves most customer issues effectively'}, 'escalation_rate': {'score': 6.0, 'reason': 'This Technical Support interaction remained at initial support level throughout 4 messages. No escalation triggers, complexity increases, or elevated support requirements emerged during the conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good'}, 'customer_effort_reduction': {'score': 6.0, 'reason': 'Customer engagement in this 4-message Technical Support interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - demonstrates good efficiency practices'}}}}}, 'analysis_timestamp': '2025-10-05T22:07:01.835445', 'analysis_method': 'LLM-based Agent Analysis', 'model_used': 'claude-4', 'agent_output': 'I\\'ll perform a complete and systematic analysis of this customer service conversation against all configured KPIs. Let me start by formatting the conversation data and then analyze each KPI thoroughly.\\n\\n<invoke name=\"conversation_formatter_tool\">\\n<parameter name=\"conversation_data\">{\"tweets\": [{\"tweet_id\": 534664, \"author_id\": \"243850\", \"role\": \"Customer\", \"inbound\": true, \"created_at\": \"2024-12-02\", \"text\": \"@Delta unacceptable the stunt the pulled. Comeplete trash. I won\\'t ever be. Back\"}, {\"tweet_id\": 534663, \"author_id\": \"243850\", \"role\": \"Customer\", \"inbound\": true, \"created_at\": \"2024-12-02\", \"text\": \"@Delta @Delta thanks for cutting my time short with my mother who I won\\'t get to see for years after I got to boot camp. This how you treat Vets? I\\'ll make that notes\"}, {\"tweet_id\": 534661, \"author_id\": \"Delta\", \"role\": \"Service Provider\", \"inbound\": false, \"created_at\": \"2024-12-02\", \"text\": \"@243850 I am very sorry that you feel this way. We are here to help if you need us. Pleas...', 'source_object_id': '68dce513b1dee7d0fab60b04', 'source_timestamp': '2025-10-05T22:07:01.835000', 'analysis_metadata': {'processed_timestamp': datetime.datetime(2025, 10, 5, 22, 7, 1, 835000), 'source_collection': 'sentiment_analysis', 'analysis_version': '4.2.0', 'model_used': 'claude-4', 'restructured_format': True}, 'persistence_metadata': {'inserted_timestamp': datetime.datetime(2025, 10, 5, 22, 7, 1, 835000), 'collection': 'agentic_analysis', 'job_name': 'conversation_performance_analysis', 'storage_type': 'mongodb'}}, {'conversation_id': 3762, 'customer': 'Delta', 'created_at': '2025-10-05T22:07:01.986389', 'created_time': '22:07:01', 'conversation_summary': {'total_messages': 2, 'customer_messages': 1, 'agent_messages': 1, 'conversation_type': 'Positive feedback', 'intent': 'Feedback', 'topic': 'General', 'final_sentiment': 'Positive', 'categorization': 'Positive feedback'}, 'performance_metrics': {'categories': {'accuracy_compliance': {'category_description': 'Measures Accuracy Compliance performance', 'overall_score': 6.0, 'kpis': {'resolution_completeness': {'score': 6.0, 'reason': \"The 2-message conversation about General followed a standard support pattern. While resolution steps may have been taken, the conversation format didn't capture detailed problem-solving documentation or explicit resolution confirmation statements.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - resolves most customer issues effectively', 'sub_kpis': {'issue_identification': {'score': 6.167928121165979, 'reason': 'Agent addressed the customer inquiry systematically. Problem recognition was handled through standard inquiry process'}, 'solution_depth': {'score': 6.7474927193653995, 'reason': 'Agent provided standard solution approach. Solution included basic resolution steps'}, 'follow_up_clarity': {'score': 5.850854714993835, 'reason': 'Agent completed resolution without explicit follow-up offer. Timeline communication was general'}, 'confirmation_process': {'score': 5.936809639286709, 'reason': 'Resolution confirmation was handled through standard completion process. Customer satisfaction was explicitly confirmed with positive feedback'}}, 'overall_score': 6.0}, 'accuracy_automated_responses': {'score': 6.0, 'reason': \"Information exchange in this General interaction was straightforward. Technical accuracy assessment requires specific factual claims or instructions that weren't prominently featured in this particular conversation format.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains good accuracy standards'}}}, 'empathy_communication': {'category_description': 'Measures Empathy Communication performance', 'overall_score': 6.21, 'kpis': {'empathy_score': {'score': 5.56, 'reason': 'In this 2-message General interaction, customer emotional expressions were minimal or indirect. The agent maintained professional communication without specific situations arising that would demonstrate empathy skills explicitly. Overall score calculated using weighted formula: 5.56', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - shows adequate emotional awareness', 'sub_kpis': {'emotion_recognition': {'score': 4.82, 'reason': 'Sub-factor analysis for Emotion Recognition based on conversation evidence', 'evidence': [], 'normalized_score': 0.964, 'confidence': 0.6, 'interpretation': 'needs improvement'}, 'acknowledgment_feelings': {'score': 6.11, 'reason': 'Sub-factor analysis for Acknowledgment of Feelings based on conversation evidence', 'evidence': [], 'normalized_score': 0.611, 'confidence': 0.65, 'interpretation': 'good'}, 'appropriate_response': {'score': 6.2, 'reason': 'Sub-factor analysis for Appropriate Response based on conversation evidence', 'evidence': [], 'normalized_score': 0.62, 'confidence': 0.6, 'interpretation': 'good'}, 'personalization': {'score': 4.5, 'reason': 'Sub-factor analysis for Personalization based on conversation evidence', 'evidence': [], 'normalized_score': 0.9, 'confidence': 0.6, 'interpretation': 'needs improvement'}, 'supportive_language': {'score': 5.35, 'reason': 'Sub-factor analysis for Supportive Language based on conversation evidence', 'evidence': [], 'normalized_score': 0.535, 'confidence': 0.6, 'interpretation': 'satisfactory - communication clarity needs improvement'}, 'active_listening': {'score': 6.53, 'reason': 'Sub-factor analysis for Active Listening Indicators based on conversation evidence', 'evidence': [], 'normalized_score': 0.653, 'confidence': 0.65, 'interpretation': 'good'}}, 'overall_score': 5.56}, 'sentiment_shift': {'score': 6.5, 'reason': \"Analysis of Sentiment Shift reveals specific evidence from the conversation. Customer responses provide evidence of the agent's performance in this area. Key evidence includes: relevant interaction ('@Delta check in @21706 was amazingly smooth this m...'). The score of 6.5 indicates good performance with clear evidence supporting this assessment.\", 'evidence': [], 'normalized_score': 0.65, 'confidence': 0.9, 'interpretation': 'good - maintains positive interaction tone'}, 'clarity_language': {'score': 6.19, 'reason': \"Agent responses averaged 0 words per message in this General discussion. Communication was functional though didn't showcase specific clarity enhancement techniques or customer comprehension confirmations. Overall score calculated using weighted formula: 6.19\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains clear communication standards', 'sub_kpis': {'readability_level': {'score': 6.08, 'reason': 'Sub-factor analysis for Readability Level based on conversation evidence', 'evidence': [], 'normalized_score': 0.608, 'confidence': 0.6, 'interpretation': 'good'}, 'jargon_usage': {'score': 6.45, 'reason': 'Sub-factor analysis for Jargon Usage based on conversation evidence', 'evidence': [], 'normalized_score': 0.645, 'confidence': 0.6, 'interpretation': 'good'}, 'sentence_structure': {'score': 6.81, 'reason': 'Sub-factor analysis for Sentence Structure based on conversation evidence', 'evidence': [], 'normalized_score': 0.681, 'confidence': 0.6, 'interpretation': 'good'}, 'coherence': {'score': 6.65, 'reason': 'Sub-factor analysis for Coherence based on conversation evidence', 'evidence': [], 'normalized_score': 0.665, 'confidence': 0.6, 'interpretation': 'good'}, 'active_voice': {'score': 5.8, 'reason': 'Sub-factor analysis for Use of Active Voice based on conversation evidence', 'evidence': [], 'normalized_score': 0.58, 'confidence': 0.6, 'interpretation': 'satisfactory'}, 'conciseness': {'score': 5.16, 'reason': 'Sub-factor analysis for Conciseness based on conversation evidence', 'evidence': [], 'normalized_score': 0.516, 'confidence': 0.6, 'interpretation': 'satisfactory'}}, 'overall_score': 6.19}, 'cultural_sensitivity': {'score': 6.0, 'reason': 'This 2-message General interaction proceeded through standard professional channels. No cultural considerations, accommodations, or sensitivity requirements emerged that would demonstrate cultural awareness capabilities.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - shows appropriate cultural sensitivity'}, 'adaptability_quotient': {'score': 6.0, 'reason': 'Agent responses in this General case followed consistent approach patterns. No specific customer preference adjustments, communication style modifications, or adaptive problem-solving variations were required or demonstrated.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - adapts well to customer needs'}, 'conversation_flow': {'score': 7.0, 'reason': \"Analysis of Conversation Flow reveals specific evidence from the conversation. Customer responses provide evidence of the agent's performance in this area. Key evidence includes: relevant interaction ('@Delta check in @21706 was amazingly smooth this m...'); relevant interaction ('@227319 Thank you for traveling with us, Kev. Enjo...'). The score of 7.0 indicates good performance with clear evidence supporting this assessment.\", 'evidence': [], 'normalized_score': 0.7, 'confidence': 0.95, 'interpretation': 'very good'}}}, 'efficiency_resolution': {'category_description': 'Measures Efficiency Resolution performance', 'overall_score': 6.0, 'kpis': {'followup_necessity': {'score': 6.0, 'reason': 'Customer engagement in this 2-message General interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good'}, 'customer_effort_score': {'score': 6.0, 'reason': 'Customer engagement in this 2-message General interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - demonstrates good efficiency practices', 'sub_kpis': {'information_gathering': {'score': 5.545742690040624, 'reason': 'Agent gathered necessary information through standard process. Information collection was streamlined and secure'}, 'process_simplification': {'score': 7.111708418871664, 'reason': 'Agent provided standard process guidance. Customer appreciated the resolution method'}, 'proactive_assistance': {'score': 7.120407849568385, 'reason': 'Agent responded to customer requests as presented. Proactive elements included acknowledging frustration and offering immediate alternative solution'}}, 'overall_score': 6.0}, 'first_response_accuracy': {'score': 6.0, 'reason': \"Information exchange in this General interaction was straightforward. Technical accuracy assessment requires specific factual claims or instructions that weren't prominently featured in this particular conversation format.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains good accuracy standards'}, 'csat_resolution': {'score': 6.0, 'reason': \"The 2-message conversation about General followed a standard support pattern. While resolution steps may have been taken, the conversation format didn't capture detailed problem-solving documentation or explicit resolution confirmation statements.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - resolves most customer issues effectively'}, 'escalation_rate': {'score': 6.0, 'reason': 'This General interaction remained at initial support level throughout 2 messages. No escalation triggers, complexity increases, or elevated support requirements emerged during the conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.7, 'interpretation': 'good'}, 'customer_effort_reduction': {'score': 6.0, 'reason': 'Customer engagement in this 2-message General interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - demonstrates good efficiency practices'}}}}}, 'analysis_timestamp': '2025-10-05T22:07:44.026420', 'analysis_method': 'LLM-based Agent Analysis', 'model_used': 'claude-4', 'agent_output': 'I\\'ll perform a complete and systematic analysis of the provided conversation data against all configured KPIs. Let me start by formatting the conversation and then analyzing each KPI systematically.\\n\\n<invoke name=\"conversation_formatter_tool\">\\n<parameter name=\"conversation_data\">{\"tweets\": [{\"tweet_id\": 471672, \"author_id\": \"227319\", \"role\": \"Customer\", \"inbound\": true, \"created_at\": \"2024-12-01\", \"text\": \"@Delta check in @21706 was amazingly smooth this morning. Hope the flight goes the same way 👍🏽\"}, {\"tweet_id\": 471671, \"author_id\": \"Delta\", \"role\": \"Service Provider\", \"inbound\": false, \"created_at\": \"2024-12-01\", \"text\": \"@227319 Thank you for traveling with us, Kev. Enjoy your trip! *ABN\"}], \"classification\": {\"categorization\": \"Positive feedback\", \"intent\": \"Feedback\", \"topic\": \"General\", \"sentiment\": \"Positive\"}}</parameter>\\n</invoke>\\n\\nNow I\\'ll systematically analyze each KPI. Let me start with the ACCURACY_COMPLIANCE category:\\n\\n<invoke name=\"configuration_tool\">\\n<parameter name...', 'source_object_id': '68dce526b1dee7d0fab60b05', 'source_timestamp': '2025-10-05T22:07:44.026000', 'analysis_metadata': {'processed_timestamp': datetime.datetime(2025, 10, 5, 22, 7, 44, 26000), 'source_collection': 'sentiment_analysis', 'analysis_version': '4.2.0', 'model_used': 'claude-4', 'restructured_format': True}, 'persistence_metadata': {'inserted_timestamp': datetime.datetime(2025, 10, 5, 22, 7, 44, 26000), 'collection': 'agentic_analysis', 'job_name': 'conversation_performance_analysis', 'storage_type': 'mongodb'}}, {'conversation_id': 4495, 'customer': 'Delta', 'created_at': '2025-10-05T22:07:44.163157', 'created_time': '22:07:44', 'conversation_summary': {'total_messages': 2, 'customer_messages': 1, 'agent_messages': 1, 'conversation_type': 'Technical Support', 'intent': 'Technical Support', 'topic': 'Technical', 'final_sentiment': 'Neutral', 'categorization': 'Technical Support'}, 'performance_metrics': {'categories': {'accuracy_compliance': {'category_description': 'Measures Accuracy Compliance performance', 'overall_score': 6.5, 'kpis': {'resolution_completeness': {'score': 7.0, 'reason': \"Analysis of Resolution Completeness reveals specific evidence from the conversation. Key evidence includes: solution-oriented response ('@253963 I’d be delighted to assist. Please follow ...'). The score of 7.0 indicates good performance with clear evidence supporting this assessment.\", 'evidence': [], 'normalized_score': 0.7, 'confidence': 0.9, 'interpretation': 'very good - resolves most customer issues effectively', 'sub_kpis': {'issue_identification': {'score': 7.167928121165979, 'reason': 'Agent addressed the customer inquiry systematically. Problem recognition was handled through standard inquiry process'}, 'solution_depth': {'score': 7.7474927193653995, 'reason': 'Agent provided standard solution approach. Solution included basic resolution steps'}, 'follow_up_clarity': {'score': 6.850854714993835, 'reason': 'Agent completed resolution without explicit follow-up offer. Timeline communication was general'}, 'confirmation_process': {'score': 6.936809639286709, 'reason': 'Resolution confirmation was handled through standard completion process. Customer satisfaction was implied through interaction completion'}}, 'overall_score': 7.0}, 'accuracy_automated_responses': {'score': 6.0, 'reason': \"Information exchange in this Technical interaction was straightforward. Technical accuracy assessment requires specific factual claims or instructions that weren't prominently featured in this particular conversation format.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains good accuracy standards'}}}, 'empathy_communication': {'category_description': 'Measures Empathy Communication performance', 'overall_score': 6.04, 'kpis': {'empathy_score': {'score': 6.06, 'reason': \"Analysis of Empathy Score reveals specific evidence from the conversation. Key evidence includes: relevant interaction ('@253963 I’d be delighted to assist. Please follow ...'). The score of 6.5 indicates good performance with clear evidence supporting this assessment. Overall score calculated using weighted formula: 6.06\", 'evidence': [], 'normalized_score': 0.65, 'confidence': 0.9, 'interpretation': 'good - shows adequate emotional awareness', 'sub_kpis': {'emotion_recognition': {'score': 5.32, 'reason': 'Sub-factor analysis for Emotion Recognition based on conversation evidence', 'evidence': [], 'normalized_score': 0.532, 'confidence': 0.6, 'interpretation': 'satisfactory'}, 'acknowledgment_feelings': {'score': 6.61, 'reason': 'Sub-factor analysis for Acknowledgment of Feelings based on conversation evidence', 'evidence': [], 'normalized_score': 0.661, 'confidence': 0.65, 'interpretation': 'good'}, 'appropriate_response': {'score': 6.7, 'reason': 'Sub-factor analysis for Appropriate Response based on conversation evidence', 'evidence': [], 'normalized_score': 0.67, 'confidence': 0.6, 'interpretation': 'good'}, 'personalization': {'score': 5.0, 'reason': 'Sub-factor analysis for Personalization based on conversation evidence', 'evidence': [], 'normalized_score': 1.0, 'confidence': 0.6, 'interpretation': 'needs improvement'}, 'supportive_language': {'score': 5.85, 'reason': 'Sub-factor analysis for Supportive Language based on conversation evidence', 'evidence': [], 'normalized_score': 0.585, 'confidence': 0.6, 'interpretation': 'satisfactory - communication clarity needs improvement'}, 'active_listening': {'score': 7.03, 'reason': 'Sub-factor analysis for Active Listening Indicators based on conversation evidence', 'evidence': [], 'normalized_score': 0.703, 'confidence': 0.65, 'interpretation': 'very good'}}, 'overall_score': 6.06}, 'sentiment_shift': {'score': 6.0, 'reason': \"Customer tone remained relatively consistent from initial contact ('@Delta I keep trying to change...') through conclusion ('@Delta I keep trying to change...'). No dramatic sentiment transformation indicators were present in this Technical interaction.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains positive interaction tone'}, 'clarity_language': {'score': 6.19, 'reason': \"Agent responses averaged 0 words per message in this Technical discussion. Communication was functional though didn't showcase specific clarity enhancement techniques or customer comprehension confirmations. Overall score calculated using weighted formula: 6.19\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains clear communication standards', 'sub_kpis': {'readability_level': {'score': 6.08, 'reason': 'Sub-factor analysis for Readability Level based on conversation evidence', 'evidence': [], 'normalized_score': 0.608, 'confidence': 0.6, 'interpretation': 'good'}, 'jargon_usage': {'score': 6.45, 'reason': 'Sub-factor analysis for Jargon Usage based on conversation evidence', 'evidence': [], 'normalized_score': 0.645, 'confidence': 0.6, 'interpretation': 'good'}, 'sentence_structure': {'score': 6.81, 'reason': 'Sub-factor analysis for Sentence Structure based on conversation evidence', 'evidence': [], 'normalized_score': 0.681, 'confidence': 0.6, 'interpretation': 'good'}, 'coherence': {'score': 6.65, 'reason': 'Sub-factor analysis for Coherence based on conversation evidence', 'evidence': [], 'normalized_score': 0.665, 'confidence': 0.6, 'interpretation': 'good'}, 'active_voice': {'score': 5.8, 'reason': 'Sub-factor analysis for Use of Active Voice based on conversation evidence', 'evidence': [], 'normalized_score': 0.58, 'confidence': 0.6, 'interpretation': 'satisfactory'}, 'conciseness': {'score': 5.16, 'reason': 'Sub-factor analysis for Conciseness based on conversation evidence', 'evidence': [], 'normalized_score': 0.516, 'confidence': 0.6, 'interpretation': 'satisfactory'}}, 'overall_score': 6.19}, 'cultural_sensitivity': {'score': 6.0, 'reason': 'This 2-message Technical interaction proceeded through standard professional channels. No cultural considerations, accommodations, or sensitivity requirements emerged that would demonstrate cultural awareness capabilities.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - shows appropriate cultural sensitivity'}, 'adaptability_quotient': {'score': 6.0, 'reason': 'Agent responses in this Technical case followed consistent approach patterns. No specific customer preference adjustments, communication style modifications, or adaptive problem-solving variations were required or demonstrated.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - adapts well to customer needs'}, 'conversation_flow': {'score': 6.0, 'reason': 'The 2-message exchange about Technical maintained basic turn-taking structure. Standard greeting-issue-response-closure pattern without notable flow disruptions or enhancement techniques.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.7, 'interpretation': 'good'}}}, 'efficiency_resolution': {'category_description': 'Measures Efficiency Resolution performance', 'overall_score': 6.17, 'kpis': {'followup_necessity': {'score': 6.0, 'reason': 'Customer engagement in this 2-message Technical interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good'}, 'customer_effort_score': {'score': 6.0, 'reason': 'Customer engagement in this 2-message Technical interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - demonstrates good efficiency practices', 'sub_kpis': {'information_gathering': {'score': 5.545742690040624, 'reason': 'Agent efficiently requested only essential information (email via DM) without excessive back-and-forth. Information collection was streamlined and secure'}, 'process_simplification': {'score': 7.111708418871664, 'reason': 'Agent provided standard process guidance. Customer appreciated the resolution method'}, 'proactive_assistance': {'score': 7.120407849568385, 'reason': 'Agent responded to customer requests as presented. Proactive elements included acknowledging frustration and offering immediate alternative solution'}}, 'overall_score': 6.0}, 'first_response_accuracy': {'score': 6.0, 'reason': \"Information exchange in this Technical interaction was straightforward. Technical accuracy assessment requires specific factual claims or instructions that weren't prominently featured in this particular conversation format.\", 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - maintains good accuracy standards'}, 'csat_resolution': {'score': 7.0, 'reason': \"Analysis of Csat Resolution reveals specific evidence from the conversation. Key evidence includes: solution-oriented response ('@253963 I’d be delighted to assist. Please follow ...'). The score of 7.0 indicates good performance with clear evidence supporting this assessment.\", 'evidence': [], 'normalized_score': 0.7, 'confidence': 0.9, 'interpretation': 'very good - resolves most customer issues effectively'}, 'escalation_rate': {'score': 6.0, 'reason': 'This Technical interaction remained at initial support level throughout 2 messages. No escalation triggers, complexity increases, or elevated support requirements emerged during the conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.7, 'interpretation': 'good'}, 'customer_effort_reduction': {'score': 6.0, 'reason': 'Customer engagement in this 2-message Technical interaction was direct. No explicit effort reduction measures, follow-up arrangements, or customer workload discussions were documented in the available conversation.', 'evidence': [], 'normalized_score': 0.6, 'confidence': 0.75, 'interpretation': 'good - demonstrates good efficiency practices'}}}}}, 'analysis_timestamp': '2025-10-05T22:08:27.805766', 'analysis_method': 'LLM-based Agent Analysis', 'model_used': 'claude-4', 'agent_output': 'I\\'ll perform a complete and systematic analysis of the provided conversation data against all configured KPIs. Let me start by formatting the conversation and then analyzing each KPI systematically.\\n\\n<invoke name=\"conversation_formatter_tool\">\\n<parameter name=\"conversation_data\">{\"tweets\": [{\"tweet_id\": 570556, \"author_id\": \"253963\", \"role\": \"Customer\", \"inbound\": true, \"created_at\": \"2024-12-03\", \"text\": \"@Delta I keep trying to change a flight on your website and getting error message. Than there is an hour long wait time to speak to someone on the phone!\"}, {\"tweet_id\": 570555, \"author_id\": \"Delta\", \"role\": \"Service Provider\", \"inbound\": false, \"created_at\": \"2024-12-03\", \"text\": \"@253963 I\\\\u2019d be delighted to assist. Please follow and DM your confirmation number.  *AFC https://t.co/6iDGBJAc2m\"}], \"classification\": {\"categorization\": \"Technical Support\", \"intent\": \"Technical Support\", \"topic\": \"Technical\", \"sentiment\": \"Neutral\"}}</parameter>\\n</invoke>\\n\\nNow I\\'ll systematically an...', 'source_object_id': '68dce53ab1dee7d0fab60b06', 'source_timestamp': '2025-10-05T22:08:27.805000', 'analysis_metadata': {'processed_timestamp': datetime.datetime(2025, 10, 5, 22, 8, 27, 805000), 'source_collection': 'sentiment_analysis', 'analysis_version': '4.2.0', 'model_used': 'claude-4', 'restructured_format': True}, 'persistence_metadata': {'inserted_timestamp': datetime.datetime(2025, 10, 5, 22, 8, 27, 805000), 'collection': 'agentic_analysis', 'job_name': 'conversation_performance_analysis', 'storage_type': 'mongodb'}}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_customer_list():\n",
        "    \"\"\"Extract unique customer list from MongoDB\"\"\"\n",
        "    if not data or \"selected_records\" not in data:\n",
        "        return [\"All\"]\n",
        "    customers = {r.get(\"customer\", \"Unknown\") for r in data[\"selected_records\"]}\n",
        "    return [\"All\"] + sorted(list(customers))"
      ],
      "metadata": {
        "id": "uvizMvB4ZkIW"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_current_month_range():\n",
        "    today = datetime.now()\n",
        "    start_date = today.replace(day=1).strftime(\"%Y-%m-%d\")\n",
        "    end_date = (today.replace(month=today.month % 12 + 1, day=1) - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
        "    return start_date, end_date"
      ],
      "metadata": {
        "id": "kJKcqkX0Z8MA"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_data(data, customer, start_date, end_date):\n",
        "    if not data or \"selected_records\" not in data:\n",
        "        return []\n",
        "    out = []\n",
        "    for r in data[\"selected_records\"]:\n",
        "        if customer != \"All\" and r.get(\"customer\") != customer:\n",
        "            continue\n",
        "        try:\n",
        "            created = r.get(\"created_at\")\n",
        "            if not created:\n",
        "                continue\n",
        "            rec_dt = datetime.fromisoformat(str(created).replace(\"Z\", \"+00:00\"))\n",
        "            start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "            end = datetime.strptime(end_date, \"%Y-%m-%d\") + timedelta(days=1)\n",
        "            if start <= rec_dt <= end:\n",
        "                out.append(r)\n",
        "        except Exception:\n",
        "            continue\n",
        "    return out"
      ],
      "metadata": {
        "id": "ueAy9QS2Z-RB"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_details_table(filtered_records):\n",
        "    if not filtered_records:\n",
        "        cols = [\"ConversationID\", \"Customer\", \"start date\", \"EndDate\", \"Sentiment\", \"Intent\",\n",
        "                \"Topic\", \"total_messages\", \"customer_messages\", \"agent_messages\",\n",
        "                \"conversation_type\", \"status\", \"Accuracy_Score\", \"Empathy_Score\", \"Efficiency_Score\"]\n",
        "        return pd.DataFrame(columns=cols)\n",
        "\n",
        "    rows = []\n",
        "    status_map = {\"Positive\": \"Closed/Resolved\", \"Neutral\": \"Needs Review\", \"Negative\": \"Escalated\"}\n",
        "\n",
        "    for r in filtered_records:\n",
        "        summary = r.get(\"conversation_summary\", {}) or {}\n",
        "        metrics = r.get(\"performance_metrics\", {}).get(\"categories\", {}) or {}\n",
        "        created_at_dt = pd.to_datetime(r.get(\"created_at\"), errors=\"coerce\")\n",
        "        start_date = created_at_dt.strftime(\"%Y-%m-%d\") if pd.notna(created_at_dt) else \"N/A\"\n",
        "\n",
        "        rows.append({\n",
        "            \"ConversationID\": r.get(\"conversation_id\"),\n",
        "            \"Customer\": r.get(\"customer\"),\n",
        "            \"start date\": start_date,\n",
        "            \"EndDate\": start_date,\n",
        "            \"Sentiment\": summary.get(\"final_sentiment\"),\n",
        "            \"Intent\": summary.get(\"intent\"),\n",
        "            \"Topic\": summary.get(\"topic\"),\n",
        "            \"total_messages\": summary.get(\"total_messages\"),\n",
        "            \"customer_messages\": summary.get(\"customer_messages\"),\n",
        "            \"agent_messages\": summary.get(\"agent_messages\"),\n",
        "            \"conversation_type\": summary.get(\"conversation_type\"),\n",
        "            \"status\": status_map.get(summary.get(\"final_sentiment\"), \"N/A\"),\n",
        "            \"Accuracy_Score\": metrics.get(\"accuracy_compliance\", {}).get(\"overall_score\"),\n",
        "            \"Empathy_Score\": metrics.get(\"empathy_communication\", {}).get(\"overall_score\"),\n",
        "            \"Efficiency_Score\": metrics.get(\"efficiency_resolution\", {}).get(\"overall_score\")\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    df[[\"Accuracy_Score\", \"Empathy_Score\", \"Efficiency_Score\"]] = df[[\"Accuracy_Score\", \"Empathy_Score\", \"Efficiency_Score\"]].fillna(0)\n",
        "    return df"
      ],
      "metadata": {
        "id": "yogrPj0XaCoe"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sentiment_chart(filtered_records):\n",
        "    fig = go.Figure()\n",
        "    if not filtered_records:\n",
        "        fig.add_annotation(text=\"No Data Found\", xref=\"paper\", yref=\"paper\", x=0.5, y=0.5, showarrow=False,\n",
        "                           font=dict(size=20, color=\"gray\"))\n",
        "        fig.update_layout(title=\"\", height=350, margin=dict(l=20, r=20, t=40, b=20))\n",
        "        return fig\n",
        "\n",
        "    counts = {}\n",
        "    for r in filtered_records:\n",
        "        s = r.get(\"conversation_summary\", {}).get(\"final_sentiment\", \"Unknown\")\n",
        "        counts[s] = counts.get(s, 0) + 1\n",
        "\n",
        "    colors = {'Positive': '#28a745', 'Neutral': '#ffc107', 'Negative': '#dc3545', 'Unknown': '#6c757d'}\n",
        "    fig = go.Figure(data=[go.Pie(labels=list(counts.keys()), values=list(counts.values()),\n",
        "                                marker=dict(colors=[colors.get(k, '#6c757d') for k in counts.keys()]),\n",
        "                                textinfo='label+percent', hovertemplate='%{label}: %{value}<extra></extra>')])\n",
        "    fig.update_layout(title=\"\", height=350, showlegend=False, margin=dict(l=20, r=20, t=40, b=20))\n",
        "    return fig"
      ],
      "metadata": {
        "id": "qeueA1M9aDz_"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_intent_chart(filtered_records):\n",
        "    fig = go.Figure()\n",
        "    if not filtered_records:\n",
        "        fig.add_annotation(text=\"No Data Found\", xref=\"paper\", yref=\"paper\", x=0.5, y=0.5, showarrow=False,\n",
        "                           font=dict(size=20, color=\"gray\"))\n",
        "        fig.update_layout(title=\"\", height=350, margin=dict(l=20, r=20, t=40, b=80))\n",
        "        return fig\n",
        "\n",
        "    counts = {}\n",
        "    for r in filtered_records:\n",
        "        k = r.get(\"conversation_summary\", {}).get(\"intent\", \"Unknown\")\n",
        "        counts[k] = counts.get(k, 0) + 1\n",
        "\n",
        "    fig = go.Figure(data=[go.Bar(x=list(counts.keys()), y=list(counts.values()),\n",
        "                                text=list(counts.values()), textposition=\"outside\")])\n",
        "    fig.update_layout(title=\"\", height=350, margin=dict(l=20, r=20, t=40, b=80), xaxis_tickangle=-45, showlegend=False)\n",
        "    return fig"
      ],
      "metadata": {
        "id": "XfrIdtgRaHAH"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_topic_chart(filtered_records):\n",
        "    fig = go.Figure()\n",
        "    if not filtered_records:\n",
        "        fig.add_annotation(text=\"No Data Found\", xref=\"paper\", yref=\"paper\", x=0.5, y=0.5, showarrow=False,\n",
        "                           font=dict(size=20, color=\"gray\"))\n",
        "        fig.update_layout(title=\"\", height=350, margin=dict(l=20, r=20, t=40, b=20))\n",
        "        return fig\n",
        "\n",
        "    counts = {}\n",
        "    for r in filtered_records:\n",
        "        k = r.get(\"conversation_summary\", {}).get(\"topic\", \"Unknown\")\n",
        "        counts[k] = counts.get(k, 0) + 1\n",
        "\n",
        "    colors = px.colors.qualitative.Set3\n",
        "    fig = go.Figure(data=[go.Pie(labels=list(counts.keys()), values=list(counts.values()),\n",
        "                                marker=dict(colors=colors[:len(counts)]),\n",
        "                                textinfo='label+percent', hovertemplate='%{label}: %{value}<extra></extra>')])\n",
        "    fig.update_layout(title=\"\", height=350, showlegend=False, margin=dict(l=20, r=20, t=40, b=20))\n",
        "    return fig"
      ],
      "metadata": {
        "id": "IuC89avwaJvI"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_performance_summary(data, filtered_records):\n",
        "    if not filtered_records:\n",
        "        empty = \"No conversations match the selected filters.\"\n",
        "        return empty, empty, empty\n",
        "    if not data or \"summary\" not in data:\n",
        "        empty = \"Performance summary data is not available.\"\n",
        "        return empty, empty, empty\n",
        "\n",
        "    summary = data[\"summary\"]\n",
        "    good = \"\\n\\n\".join([f\"{i+1}. {p}\" for i, p in enumerate(summary.get(\"what_went_well\", [])[:4])])\n",
        "    bad = \"\\n\\n\".join([f\"{i+1}. {p}\" for i, p in enumerate(summary.get(\"what_needs_improvement\", [])[:3])])\n",
        "    improve = \"\\n\\n\".join([f\"{i+1}. {p}\" for i, p in enumerate(summary.get(\"training_needs\", [])[:3])])\n",
        "    return good, bad, improve"
      ],
      "metadata": {
        "id": "4DVyrLDjaL7n"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_combination_list(data):\n",
        "    \"\"\"Extract unique (Sentiment × Intent × Topic) combinations from data\"\"\"\n",
        "    if not data or \"selected_records\" not in data:\n",
        "        return []\n",
        "\n",
        "    combos = []\n",
        "    for rec in data[\"selected_records\"]:\n",
        "        summary = rec.get(\"conversation_summary\", {}) or {}\n",
        "        sentiment = (summary.get(\"final_sentiment\") or \"N/A\").strip().title()\n",
        "        intent = (summary.get(\"intent\") or \"N/A\").strip().title()\n",
        "        topic = (summary.get(\"topic\") or \"N/A\").strip().title()\n",
        "        combo = f\"{sentiment}|{intent}|{topic}\"\n",
        "        combos.append(combo)\n",
        "\n",
        "    return sorted(set(combos))"
      ],
      "metadata": {
        "id": "24Hkku9naOsn"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_combination_performance_charts(data, selected_combo):\n",
        "    \"\"\"Create three separate performance charts for Accuracy, Empathy, and Efficiency\"\"\"\n",
        "    empty_fig = go.Figure().update_layout(title=\"No Data\", height=400)\n",
        "\n",
        "    if not data or \"aggregated_insights\" not in data:\n",
        "        return empty_fig, empty_fig, empty_fig\n",
        "\n",
        "    combo_analysis = data[\"aggregated_insights\"].get(\"combination_analysis\", {})\n",
        "\n",
        "    if not combo_analysis or selected_combo not in combo_analysis:\n",
        "        return empty_fig, empty_fig, empty_fig\n",
        "\n",
        "    combo_data = combo_analysis[selected_combo]\n",
        "    perf_avg = combo_data.get(\"performance_averages\", {})\n",
        "\n",
        "    # Helper function to create chart\n",
        "    def create_category_chart(category_data, category_name, color_base):\n",
        "        if not category_data:\n",
        "            return go.Figure().update_layout(title=f\"No {category_name} Data\", height=400)\n",
        "\n",
        "        labels = []\n",
        "        scores = []\n",
        "        normalized_scores = []\n",
        "\n",
        "        # Add overall score first\n",
        "        overall = category_data.get(\"overall_score\", {})\n",
        "        if overall:\n",
        "            labels.append(\"Overall Score\")\n",
        "            scores.append(overall.get(\"score\", 0))\n",
        "            normalized_scores.append(overall.get(\"normalized_score\", 0))\n",
        "\n",
        "        # Add all other components (flatten the structure)\n",
        "        for key, value in category_data.items():\n",
        "            if key == \"overall_score\":\n",
        "                continue\n",
        "            if isinstance(value, dict):\n",
        "                # This is a component (like resolution_completeness, empathy_score, etc.)\n",
        "                comp_name = key.replace(\"_\", \" \").title()\n",
        "                comp_score = value.get(\"score\", 0)\n",
        "                comp_norm = value.get(\"normalized_score\", 0)\n",
        "\n",
        "                labels.append(comp_name)\n",
        "                scores.append(comp_score)\n",
        "                normalized_scores.append(comp_norm)\n",
        "\n",
        "                # Add sub-components if they exist (like resolution_completeness_issue_identification)\n",
        "                for sub_key, sub_value in value.items():\n",
        "                    if sub_key in [\"score\", \"normalized_score\", \"interpretation\"]:\n",
        "                        continue\n",
        "                    if isinstance(sub_value, (int, float)):\n",
        "                        sub_name = f\"  → {sub_key.replace('_', ' ').title()}\"\n",
        "                        labels.append(sub_name)\n",
        "                        scores.append(sub_value)\n",
        "                        normalized_scores.append(sub_value / 10.0 if sub_value > 1 else sub_value)\n",
        "\n",
        "        # Create bar chart with normalized scores\n",
        "        colors_list = []\n",
        "        for norm_score in normalized_scores:\n",
        "            score_val = norm_score * 10 if norm_score <= 1 else norm_score\n",
        "            if score_val >= 7:\n",
        "                colors_list.append(color_base[0])  # Green\n",
        "            elif score_val >= 6:\n",
        "                colors_list.append(color_base[1])  # Orange\n",
        "            else:\n",
        "                colors_list.append(color_base[2])  # Red\n",
        "\n",
        "        fig = go.Figure(data=[\n",
        "            go.Bar(\n",
        "                y=labels,\n",
        "                x=normalized_scores,\n",
        "                orientation='h',\n",
        "                text=[f\"{s:.3f}\" for s in normalized_scores],\n",
        "                textposition=\"outside\",\n",
        "                marker_color=colors_list,\n",
        "                hovertemplate='%{y}: %{x:.3f}<extra></extra>'\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        fig.update_layout(\n",
        "            #title=f\"{category_name} Components\",\n",
        "            xaxis_title=\"Normalized Score (0-1)\",\n",
        "            yaxis_title=\"Component\",\n",
        "            height=max(400, len(labels) * 30),\n",
        "            showlegend=False,\n",
        "            xaxis=dict(range=[0, 1]),\n",
        "            margin=dict(l=250, r=50, t=60, b=50)\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    # Create three charts\n",
        "    acc_data = perf_avg.get(\"accuracy_compliance\", {})\n",
        "    emp_data = perf_avg.get(\"empathy_communication\", {})\n",
        "    eff_data = perf_avg.get(\"efficiency_resolution\", {})\n",
        "\n",
        "    acc_fig = create_category_chart(acc_data, \"Accuracy & Compliance\", [\"#27ae60\", \"#f39c12\", \"#e74c3c\"])\n",
        "    emp_fig = create_category_chart(emp_data, \"Empathy & Communication\", [\"#3498db\", \"#f39c12\", \"#e74c3c\"])\n",
        "    eff_fig = create_category_chart(eff_data, \"Efficiency & Resolution\", [\"#9b59b6\", \"#f39c12\", \"#e74c3c\"])\n",
        "\n",
        "    return acc_fig, emp_fig, eff_fig"
      ],
      "metadata": {
        "id": "y5xEE2BnaRQv"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_layered_donut_for_record(record):\n",
        "    \"\"\"Build a sunburst for a single conversation record with category-based colors and detailed hover info.\"\"\"\n",
        "    empty_fig = go.Figure().update_layout(title=\"No Data\", height=450)\n",
        "    if not record:\n",
        "        return empty_fig\n",
        "\n",
        "    # Define a Color Map for Categories\n",
        "    color_map = {\n",
        "        \"Accuracy Compliance\": \"#27ae60\",  # Green\n",
        "        \"Empathy Communication\": \"#3498db\",  # Blue\n",
        "        \"Efficiency Resolution\": \"#9b59b6\",  # Purple\n",
        "        \"\": \"#6c757d\" # Default/N/A\n",
        "    }\n",
        "\n",
        "    categories = record.get(\"performance_metrics\", {}).get(\"categories\", {})\n",
        "    rows = []\n",
        "    hover_lookup = {}  # Store hover info by full path\n",
        "\n",
        "    for cat_key, cat_data in categories.items():\n",
        "        cat_name = cat_key.replace(\"_\", \" \").title()\n",
        "        base_color = color_map.get(cat_name, color_map[\"\"])\n",
        "        kpis = cat_data.get(\"kpis\", {}) or {}\n",
        "\n",
        "        # Store category hover info\n",
        "        cat_overall_score = cat_data.get(\"overall_score\", \"N/A\")\n",
        "        hover_lookup[cat_name] = f\"Overall Score: {cat_overall_score}\"\n",
        "\n",
        "        if not kpis:\n",
        "            cat_score = cat_data.get(\"overall_score\")\n",
        "            if cat_score is not None:\n",
        "                rows.append({\n",
        "                    \"category\": cat_name,\n",
        "                    \"kpi\": \"\",\n",
        "                    \"sub_kpi\": \"\",\n",
        "                    \"score\": float(cat_score),\n",
        "                    \"color_category\": base_color\n",
        "                })\n",
        "            continue\n",
        "\n",
        "        for kpi_key, kpi_data in kpis.items():\n",
        "            kpi_name = kpi_key.replace(\"_\", \" \").title()\n",
        "\n",
        "            kpi_score = kpi_data.get(\"normalized_score\") or kpi_data.get(\"score\")\n",
        "            if kpi_score is None:\n",
        "                kpi_score = 0.5\n",
        "\n",
        "            # Store KPI hover info\n",
        "            kpi_normalized_score = kpi_data.get(\"normalized_score\", \"N/A\")\n",
        "            kpi_confidence = kpi_data.get(\"confidence\", \"N/A\")\n",
        "            kpi_interpretation = kpi_data.get(\"interpretation\", \"N/A\")\n",
        "            hover_lookup[kpi_name] = (\n",
        "                f\"Normalized Score: {kpi_normalized_score}<br>\"\n",
        "                f\"Confidence: {kpi_confidence}<br>\"\n",
        "                f\"Interpretation: {kpi_interpretation}\"\n",
        "            )\n",
        "\n",
        "            sub_kpis = kpi_data.get(\"sub_kpis\", {}) or {}\n",
        "\n",
        "            if sub_kpis and isinstance(sub_kpis, dict):\n",
        "                for sub_key, sub_data in sub_kpis.items():\n",
        "                    sub_name = sub_key.replace(\"_\", \" \").title()\n",
        "\n",
        "                    if isinstance(sub_data, dict):\n",
        "                        sub_score = sub_data.get(\"normalized_score\") or sub_data.get(\"score\")\n",
        "                        if sub_score is None:\n",
        "                            sub_score = 0.5\n",
        "                        if sub_score > 1:\n",
        "                            sub_score = sub_score / 10.0\n",
        "\n",
        "                        # Store Sub-KPI hover info\n",
        "                        sub_reason = sub_data.get(\"reason\", \"N/A\")\n",
        "                        if len(str(sub_reason)) > 150:\n",
        "                            sub_reason = str(sub_reason)[:150] + \"...\"\n",
        "                        sub_normalized_score = sub_data.get(\"normalized_score\", \"N/A\")\n",
        "                        sub_confidence = sub_data.get(\"confidence\", \"N/A\")\n",
        "                        sub_interpretation = sub_data.get(\"interpretation\", \"N/A\")\n",
        "\n",
        "                        hover_lookup[sub_name] = (\n",
        "                            f\"Normalized Score: {sub_normalized_score}<br>\"\n",
        "                            f\"Confidence: {sub_confidence}<br>\"\n",
        "                            f\"Interpretation: {sub_interpretation}<br>\"\n",
        "                            f\"Reason: {sub_reason}\"\n",
        "                        )\n",
        "                    else:\n",
        "                        sub_score = 0.5\n",
        "\n",
        "                    rows.append({\n",
        "                        \"category\": cat_name,\n",
        "                        \"kpi\": kpi_name,\n",
        "                        \"sub_kpi\": sub_name,\n",
        "                        \"score\": float(sub_score),\n",
        "                        \"color_category\": base_color\n",
        "                    })\n",
        "            else:\n",
        "                if kpi_score > 1:\n",
        "                    kpi_score = kpi_score / 10.0\n",
        "\n",
        "                rows.append({\n",
        "                    \"category\": cat_name,\n",
        "                    \"kpi\": kpi_name,\n",
        "                    \"sub_kpi\": \"\",\n",
        "                    \"score\": float(kpi_score),\n",
        "                    \"color_category\": base_color\n",
        "                })\n",
        "\n",
        "    if not rows:\n",
        "        return empty_fig\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    df[\"level1\"] = df[\"category\"]\n",
        "    df[\"level2\"] = df.apply(lambda r: r[\"kpi\"] if r[\"kpi\"] else \"\", axis=1)\n",
        "    df[\"level3\"] = df.apply(lambda r: r[\"sub_kpi\"] if r[\"sub_kpi\"] else \"\", axis=1)\n",
        "\n",
        "    df = df[~((df[\"level2\"] == \"\") & (df[\"level3\"] == \"\"))]\n",
        "\n",
        "    if df.empty:\n",
        "        return empty_fig\n",
        "\n",
        "    fig = px.sunburst(\n",
        "        df,\n",
        "        path=[\"level1\", \"level2\", \"level3\"],\n",
        "        values=\"score\",\n",
        "        color=\"color_category\",\n",
        "        color_discrete_map={k: v for k, v in color_map.items()},\n",
        "        title=f\"Category → KPI → Sub-KPI (Conversation {record.get('conversation_id')})\",\n",
        "    )\n",
        "\n",
        "    fig.update_coloraxes(showscale=False)\n",
        "\n",
        "    # Extract labels from the created figure and map to hover info\n",
        "    labels = fig.data[0].labels\n",
        "    customdata = []\n",
        "\n",
        "    for label in labels:\n",
        "        if label in hover_lookup:\n",
        "            customdata.append(hover_lookup[label])\n",
        "        else:\n",
        "            customdata.append(\"\")\n",
        "\n",
        "    fig.update_traces(\n",
        "        textinfo=\"label+percent parent\",\n",
        "        insidetextorientation=\"radial\",\n",
        "        hovertemplate='<b>%{label}</b><br>%{customdata}<extra></extra>',\n",
        "        customdata=customdata\n",
        "    )\n",
        "\n",
        "    fig.update_layout(margin=dict(t=50, l=10, r=10, b=10), height=650)\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "id": "dFkee4PmaTu9"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_context_table(summary):\n",
        "    fields = [\n",
        "        (\"Intent\", summary.get(\"intent\", \"N/A\")),\n",
        "        (\"Topic\", summary.get(\"topic\", \"N/A\")),\n",
        "        (\"Sentiment\", summary.get(\"final_sentiment\", \"N/A\")),\n",
        "        (\"Type\", summary.get(\"conversation_type\", \"N/A\")),\n",
        "        (\"Total Messages\", summary.get(\"total_messages\", \"N/A\")),\n",
        "        (\"Customer Messages\", summary.get(\"customer_messages\", \"N/A\")),\n",
        "        (\"Agent Messages\", summary.get(\"agent_messages\", \"N/A\")),\n",
        "        (\"Categorization\", summary.get(\"categorization\", \"N/A\")),\n",
        "    ]\n",
        "\n",
        "    html = \"\"\"\n",
        "    <table style=\"width:100%; border-collapse: collapse; font-size: 14px; margin-bottom: 20px;\">\n",
        "        <tbody>\n",
        "    \"\"\"\n",
        "    num_fields = len(fields)\n",
        "    num_rows = (num_fields + 1) // 2\n",
        "    for i in range(num_rows):\n",
        "        label1, value1 = fields[i]\n",
        "        if i + num_rows < num_fields:\n",
        "            label2, value2 = fields[i + num_rows]\n",
        "        else:\n",
        "            label2, value2 = (\"\", \"\")\n",
        "        html += f\"\"\"\n",
        "        <tr>\n",
        "            <td style=\"border: 1px solid #ddd; padding: 8px; background-color: #f7f7f7; font-weight: bold; width: 25%;\">{label1}</td>\n",
        "            <td style=\"border: 1px solid #ddd; padding: 8px; width: 25%;\">{value1}</td>\n",
        "            <td style=\"border: 1px solid #ddd; padding: 8px; background-color: #f7f7f7; font-weight: bold; width: 25%;\">{label2}</td>\n",
        "            <td style=\"border: 1px solid #ddd; padding: 8px; width: 25%;\">{value2}</td>\n",
        "        </tr>\n",
        "        \"\"\"\n",
        "    html += \"\"\"\n",
        "        </tbody>\n",
        "    </table>\n",
        "    \"\"\"\n",
        "    return html"
      ],
      "metadata": {
        "id": "MV_Yx0MHaXrZ"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_conversation_summary_html_and_donut(record):\n",
        "    \"\"\"Returns (context_html, donut_figure)\"\"\"\n",
        "    empty_fig = go.Figure().update_layout(title=\"No Data\", height=450)\n",
        "    if not record:\n",
        "        return \"<p>No conversation data found.</p>\", empty_fig\n",
        "\n",
        "    summary = record.get(\"conversation_summary\", {}) or {}\n",
        "    context_html = f\"\"\"\n",
        "    <div style=\"font-family: Arial, sans-serif; padding: 0 20px; max-width: 1000px; margin: auto;\">\n",
        "        <h3 style=\"padding-bottom: 5px; color: #3498db; margin-top: 0;\">Conversation Context Table</h3>\n",
        "        {_create_context_table(summary)}\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    donut_fig = create_layered_donut_for_record(record)\n",
        "    return context_html, donut_fig"
      ],
      "metadata": {
        "id": "mgeFPwOSaZy_"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_row_selection(evt: gr.SelectData, details_df, all_data):\n",
        "    \"\"\"On row selection -> return summary_title, context_html, donut_fig, switch to Conversation Context tab\"\"\"\n",
        "    if evt is None or evt.index is None or details_df is None or details_df.empty:\n",
        "        return \"Click a Conversation ID for details.\", \"<p>No conversation selected.</p>\", go.Figure().update_layout(title=\"No Data\", height=450), gr.Tabs(selected=0)\n",
        "\n",
        "    selected_row_index = evt.index[0]\n",
        "    if selected_row_index >= len(details_df):\n",
        "        return \"Click a Conversation ID for details.\", \"<p>No conversation selected.</p>\", go.Figure().update_layout(title=\"No Data\", height=450), gr.Tabs(selected=0)\n",
        "\n",
        "    if 'ConversationID' not in details_df.columns:\n",
        "        return \"Click a Conversation ID for details.\", \"<p>Error: ConversationID column missing in table.</p>\", go.Figure().update_layout(title=\"No Data\", height=450), gr.Tabs(selected=0)\n",
        "\n",
        "    conversation_id = details_df.iloc[selected_row_index][\"ConversationID\"]\n",
        "    full_record = next((rec for rec in all_data.get(\"selected_records\", []) if str(rec.get(\"conversation_id\")) == str(conversation_id)), None)\n",
        "\n",
        "    if full_record:\n",
        "        context_html, donut_fig = create_conversation_summary_html_and_donut(full_record)\n",
        "    else:\n",
        "        context_html = \"<p>No conversation data found.</p>\"\n",
        "        donut_fig = go.Figure().update_layout(title=\"No Data\", height=450)\n",
        "\n",
        "    new_title = f\"Context for Conversation ID: {conversation_id}\"\n",
        "    return new_title, context_html, donut_fig, gr.Tabs(selected=1)"
      ],
      "metadata": {
        "id": "ahBYsLhoacAI"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dashboard():\n",
        "    default_start, default_end = get_current_month_range()\n",
        "    full_data = load_json_data() or {}\n",
        "\n",
        "    tab_selector_state = gr.State(value=0)\n",
        "    initial_fig = go.Figure().update_layout(title=\"Select a Conversation ID\", height=450)\n",
        "\n",
        "    with gr.Blocks(title=\"Customer Service Conversation Analytics Dashboard\", theme=gr.themes.Soft()) as dashboard:\n",
        "        gr.Markdown(\"# Customer Service Conversation Analytics Dashboard\")\n",
        "        gr.Markdown(\"Monitor and analyze AI agent performance metrics across customer conversations\")\n",
        "\n",
        "        all_data_state = gr.State(value=full_data)\n",
        "\n",
        "        with gr.Tabs(selected=tab_selector_state.value) as tabs:\n",
        "            # Dashboard Overview Tab\n",
        "            with gr.TabItem(\"Dashboard Overview\", id=0):\n",
        "                with gr.Row():\n",
        "                    customer_dropdown = gr.Dropdown(label=\"Customer Name\", choices=get_customer_list(), value=\"All\", interactive=True)\n",
        "                    start_date = gr.Textbox(label=\"Start Date\", value=default_start, placeholder=\"YYYY-MM-DD\")\n",
        "                    end_date = gr.Textbox(label=\"End Date\", value=default_end, placeholder=\"YYYY-MM-DD\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    refresh_btn = gr.Button(\"Refresh Dashboard\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                gr.Markdown(\"---\")\n",
        "                gr.Markdown(\"## Conversation Details\")\n",
        "                filtered_results_md = gr.Markdown(value=\"**Filtered Results:** 0 conversations analyzed\")\n",
        "\n",
        "                gr.Markdown(\"### Combination Types (Click to view details)\")\n",
        "\n",
        "                combo_list = get_combination_list(full_data)\n",
        "                if combo_list:\n",
        "                    # Get conversation counts for each combination\n",
        "                    combo_analysis = full_data.get(\"aggregated_insights\", {}).get(\"combination_analysis\", {})\n",
        "\n",
        "                    with gr.Row():\n",
        "                        combo_buttons = []\n",
        "                        for combo in combo_list:\n",
        "                            # Get count for this combination\n",
        "                            count = combo_analysis.get(combo, {}).get(\"conversation_count\", 0)\n",
        "                            combo_display = f\"{combo.replace('|', ' | ')} ({count})\"\n",
        "                            btn = gr.Button(combo_display, variant=\"secondary\", size=\"sm\")\n",
        "                            combo_buttons.append((btn, combo))\n",
        "\n",
        "                details_table = gr.Dataframe(label=\"Conversation Details (Click a row for Context)\", interactive=False)\n",
        "\n",
        "                gr.Markdown(\"---\")\n",
        "                gr.Markdown(\"## Visual Analytics\")\n",
        "                with gr.Row():\n",
        "                    sentiment_plot = gr.Plot(label=\"Sentiment Distribution\")\n",
        "                    intent_plot = gr.Plot(label=\"Intent Distribution\")\n",
        "                    topic_plot = gr.Plot(label=\"Topic Distribution\")\n",
        "\n",
        "                gr.Markdown(\"---\")\n",
        "                gr.Markdown(\"## AI Agent Performance Summary\")\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"### GOOD (What's Working Well)\")\n",
        "                        good_summary = gr.Markdown(value=\"Click 'Refresh Dashboard' to load summary.\")\n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"### BAD (Issues Identified)\")\n",
        "                        bad_summary = gr.Markdown(value=\"Click 'Refresh Dashboard' to load summary.\")\n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"### IMPROVEMENTS (Action Items)\")\n",
        "                        improve_summary = gr.Markdown(value=\"Click 'Refresh Dashboard' to load summary.\")\n",
        "\n",
        "            # Conversation Context Tab\n",
        "            with gr.TabItem(\"Conversation Context\", id=1):\n",
        "                summary_title = gr.Markdown(\"Click a Conversation ID for details.\")\n",
        "                gr.Markdown(\"---\")\n",
        "                gr.Markdown(\"## Conversation Context\")\n",
        "                conversation_context_html = gr.HTML(\"<p>Select a conversation from the Dashboard Overview tab to see its detailed context.</p>\")\n",
        "                donut_plot = gr.Plot(label=\"Category → KPI → Sub-KPI\", value=initial_fig)\n",
        "\n",
        "            # Combination Details Tab\n",
        "            with gr.TabItem(\"Combination Details\", id=2):\n",
        "                gr.Markdown(\"# Combination Performance Details\")\n",
        "                gr.Markdown(\"Click on a combination badge in the Dashboard Overview tab to view detailed performance metrics\")\n",
        "\n",
        "                gr.Markdown(\"---\")\n",
        "\n",
        "                # Three separate charts\n",
        "                with gr.Row():\n",
        "                    accuracy_plot = gr.Plot(label=\"Accuracy & Compliance Components\", value=go.Figure().update_layout(title=\"Select a combination from Dashboard Overview\", height=400))\n",
        "\n",
        "                with gr.Row():\n",
        "                    empathy_plot = gr.Plot(label=\"Empathy & Communication Components\", value=go.Figure().update_layout(title=\"Select a combination from Dashboard Overview\", height=400))\n",
        "\n",
        "                with gr.Row():\n",
        "                    efficiency_plot = gr.Plot(label=\"Efficiency & Resolution Components\", value=go.Figure().update_layout(title=\"Select a combination from Dashboard Overview\", height=400))\n",
        "\n",
        "        # Callbacks\n",
        "        def load_and_update(cust, sd, ed):\n",
        "            data = load_json_data()\n",
        "            if not data:\n",
        "                empty_df = pd.DataFrame(columns=[\n",
        "                    'ConversationID', 'Customer', 'start date', 'EndDate', 'Sentiment', 'Intent',\n",
        "                    'Topic', 'total_messages', 'customer_messages', 'agent_messages',\n",
        "                    'conversation_type', 'status', 'Accuracy_Score', 'Empathy_Score', 'Efficiency_Score'\n",
        "                ])\n",
        "                empty_fig = go.Figure().update_layout(title=\"No Data\", height=350)\n",
        "                empty_msg = \"Error loading data\"\n",
        "                return empty_df, empty_fig, empty_fig, empty_fig, empty_msg, empty_msg, empty_msg, gr.Dropdown(choices=[\"All\"], value=\"All\"), \"**Filtered Results:** 0 conversations analyzed\", \"Click a Conversation ID for details.\"\n",
        "\n",
        "            filtered = filter_data(data, cust, sd, ed)\n",
        "            details_df = create_details_table(filtered)\n",
        "            sent_fig = create_sentiment_chart(filtered)\n",
        "            intent_fig = create_intent_chart(filtered)\n",
        "            topic_fig = create_topic_chart(filtered)\n",
        "            good_txt, bad_txt, improve_txt = create_performance_summary(data, filtered)\n",
        "            customers = get_customer_list()\n",
        "\n",
        "            filtered_count_msg = f\"**Filtered Results:** {len(details_df)} conversations analyzed\"\n",
        "            return details_df, sent_fig, intent_fig, topic_fig, good_txt, bad_txt, improve_txt, gr.Dropdown(choices=customers, value=cust), filtered_count_msg, \"Click a Conversation ID for details.\"\n",
        "\n",
        "        def handle_combo_button_click(combo_key):\n",
        "            \"\"\"Handle combination button click\"\"\"\n",
        "            data = load_json_data()\n",
        "            if not data:\n",
        "                empty_fig = go.Figure().update_layout(title=\"No Data\", height=400)\n",
        "                return gr.Tabs(selected=2), empty_fig, empty_fig, empty_fig\n",
        "\n",
        "            acc_fig, emp_fig, eff_fig = create_combination_performance_charts(data, combo_key)\n",
        "            return gr.Tabs(selected=2), acc_fig, emp_fig, eff_fig\n",
        "\n",
        "        refresh_btn.click(\n",
        "            fn=load_and_update,\n",
        "            inputs=[customer_dropdown, start_date, end_date],\n",
        "            outputs=[details_table, sentiment_plot, intent_plot, topic_plot,\n",
        "                     good_summary, bad_summary, improve_summary,\n",
        "                     customer_dropdown, filtered_results_md, summary_title]\n",
        "        )\n",
        "\n",
        "        details_table.select(\n",
        "            fn=handle_row_selection,\n",
        "            inputs=[details_table, all_data_state],\n",
        "            outputs=[summary_title, conversation_context_html, donut_plot, tabs],\n",
        "            queue=False\n",
        "        )\n",
        "\n",
        "        if combo_list:\n",
        "            for btn, combo_key in combo_buttons:\n",
        "                btn.click(\n",
        "                    fn=lambda c=combo_key: handle_combo_button_click(c),\n",
        "                    inputs=[],\n",
        "                    outputs=[tabs, accuracy_plot, empathy_plot, efficiency_plot]\n",
        "                )\n",
        "\n",
        "        def update_with_count(customer, start_date, end_date):\n",
        "            details_df, sentiment_fig, intent_fig, topic_fig, good_txt, bad_txt, improve_txt, _, filtered_count_msg, _ = load_and_update(customer, start_date, end_date)\n",
        "            return details_df, sentiment_fig, intent_fig, topic_fig, good_txt, bad_txt, improve_txt, filtered_count_msg\n",
        "\n",
        "        customer_dropdown.change(\n",
        "            fn=update_with_count,\n",
        "            inputs=[customer_dropdown, start_date, end_date],\n",
        "            outputs=[details_table, sentiment_plot, intent_plot, topic_plot,\n",
        "                     good_summary, bad_summary, improve_summary, filtered_results_md]\n",
        "        )\n",
        "\n",
        "        start_date.change(\n",
        "            fn=update_with_count,\n",
        "            inputs=[customer_dropdown, start_date, end_date],\n",
        "            outputs=[details_table, sentiment_plot, intent_plot, topic_plot,\n",
        "                     good_summary, bad_summary, improve_summary, filtered_results_md]\n",
        "        )\n",
        "\n",
        "        end_date.change(\n",
        "            fn=update_with_count,\n",
        "            inputs=[customer_dropdown, start_date, end_date],\n",
        "            outputs=[details_table, sentiment_plot, intent_plot, topic_plot,\n",
        "                     good_summary, bad_summary, improve_summary, filtered_results_md]\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\"*Dashboard created with Gradio - Data updates in real-time based on filters*\")\n",
        "\n",
        "    return dashboard"
      ],
      "metadata": {
        "id": "0KeZ6I2tac-g"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the dashboard\n",
        "if __name__ == \"__main__\":\n",
        "    dashboard = create_dashboard()\n",
        "    if dashboard:\n",
        "        dashboard.launch(share=True, debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "wGbJI7j1ZVIc",
        "outputId": "2c3f8a51-42bc-4f1d-aa81-4bd56fb965d6"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://307106d4fed7d451e0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://307106d4fed7d451e0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}