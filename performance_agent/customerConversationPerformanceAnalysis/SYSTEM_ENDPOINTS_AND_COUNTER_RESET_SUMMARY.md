# System Endpoints and Counter Reset Summary

## Overview
This document provides a comprehensive overview of all exposed endpoints in the Customer Conversation Performance Analysis system and the counter reset functionality.

## 🌐 Exposed API Endpoints

### 1. Reporting API Server
**Base URL:** `http://localhost:8000` (when running `python src/reporting_api.py`)

#### Endpoints:
- **GET** `/` - Root endpoint with API information
- **GET** `/health` - Health check endpoint
- **GET** `/api/conversations` - Get all analyzed conversations
- **GET** `/api/conversations/{conversation_id}` - Get specific conversation analysis
- **GET** `/api/metrics/summary` - Get performance metrics summary
- **GET** `/api/kpis` - Get KPI analysis results
- **GET** `/api/collections` - Get MongoDB collection information

### 2. LLM Agent API Server
**Base URL:** `http://localhost:8001` (when running `python src/llm_agent_api.py`)

#### Endpoints:
- **POST** `/analyze` - Analyze conversation performance using LLM
- **GET** `/health` - Health check endpoint
- **GET** `/collections` - Get available MongoDB collections

### 3. Enhanced API Server
**Base URL:** `http://localhost:8002` (when running `python src/enhanced_api.py`)

#### Endpoints:
- **POST** `/analyze-conversation` - Enhanced conversation analysis
- **GET** `/health` - Health check endpoint

## 📊 Data Collections in MongoDB

### Primary Database: `csai`

#### Source Collections (Input Data):
1. **`sentimental_analysis`** - 300 documents
   - Main collection for sentiment analysis data
   - Fields: `_id`, `conversation_number`, `customer`, `tweets`, `source_document_id`, `classification`, `processed_at`, `retry_count`

2. **`conversation_set`** - 300 documents
   - Conversation metadata and processing status
   - Fields: `_id`, `conversation_number`, `customer`, `tweets`, `last_processed_at`, `processing_attempts`, `status`

3. **`messages`** - 5,442 documents
   - Raw message data
   - Fields: `_id`, `conversation_number`, `tweets`

4. **`Testing_Vivek`** - 10,150 documents
   - Large test dataset
   - Fields: `_id`, `conversation_number`, `tweets`

5. **`Capstone Sample`** - 20 documents
   - Sample dataset for testing
   - Fields: `_id`, `conversation_number`, `tweets`

#### Output Collections:
1. **`agentic_analysis`** - 0 documents (target for processed results)
   - Stores performance analysis results
   - Generated by periodic job processing

2. **`job_state`** - 0 documents (processing tracker)
   - Tracks processing progress and checkpoints
   - Used for incremental processing

## 🔄 Counter Reset Functionality

### Purpose
Reset the processing counter so that all records from source collections can be processed again by the periodic job service.

### Available Reset Scripts:

#### 1. Basic Reset Script
```bash
python reset_sentiment_analysis_counter.py
```
- Resets counter for default collection
- Includes backup functionality

#### 2. Advanced Reset Script (Recommended)
```bash
python reset_processing_counter_corrected.py
```

**Usage Options:**
```bash
# Reset for sentimental_analysis collection (default)
python reset_processing_counter_corrected.py

# Reset for specific collection
python reset_processing_counter_corrected.py --collection sentimental_analysis

# Reset without backup
python reset_processing_counter_corrected.py --no-backup

# Reset without confirmation prompt
python reset_processing_counter_corrected.py --no-confirm

# Reset for different database
python reset_processing_counter_corrected.py --db-name custom_db

# Reset with custom MongoDB connection
python reset_processing_counter_corrected.py --connection-string "mongodb://custom:27017/"
```

### Reset Process:
1. **Connect** to MongoDB database
2. **Analyze** current processing state
3. **Show** available collections and record counts
4. **Backup** current job state (optional)
5. **Reset** the job state counter
6. **Verify** reset was successful
7. **Display** impact summary

### Current Status (Post-Reset):
- ✅ **Counter successfully reset**
- 📊 **300 records** ready for processing in `sentimental_analysis`
- 🎯 **Processing will start from the beginning**
- 🔄 **No existing job state** - fresh start

## 🚀 Running the System

### 1. Start API Servers
```bash
# Terminal 1: Start Reporting API
python src/reporting_api.py

# Terminal 2: Start LLM Agent API  
python src/llm_agent_api.py

# Terminal 3: Start Enhanced API
python src/enhanced_api.py
```

### 2. Process Data
```bash
# Run periodic job to process all 300 records
python run_periodic_job.py
```

### 3. Test Endpoints
```bash
# Test reporting API
python test_reporting_api_with_actual_data.py

# Test direct MongoDB queries
python test_direct_mongodb_query.py
```

## 📈 Processing Flow

```
┌─────────────────────┐    ┌─────────────────────┐    ┌─────────────────────┐
│  sentimental_       │───▶│  Periodic Job       │───▶│  agentic_analysis   │
│  analysis           │    │  Service            │    │  (Results)          │
│  (300 records)      │    │                     │    │  (0 → 300 records)  │
└─────────────────────┘    └─────────────────────┘    └─────────────────────┘
                                      │
                                      ▼
                           ┌─────────────────────┐
                           │  job_state          │
                           │  (Progress Tracker) │
                           │  (Reset ✅)         │
                           └─────────────────────┘
```

## 🔧 Configuration Files

### Key Configuration:
- `config/periodic_job_config.yaml` - Periodic job settings
- `config/agent_performance_config.yaml` - Performance analysis settings
- `config/aicore_credentials.yaml` - AI Core credentials

### Environment Variables:
- `MONGODB_CONNECTION_STRING` - MongoDB connection string
- `AICORE_*` - SAP AI Core credentials

## 📝 Usage Examples

### Reset Counter and Process Data:
```bash
# 1. Reset the counter
python reset_processing_counter_corrected.py --collection sentimental_analysis

# 2. Run processing
python run_periodic_job.py

# 3. Check results via API
curl http://localhost:8000/api/conversations
```

### Check System Status:
```bash
# Check collections
python check_mongodb_collections.py

# Test API endpoints
curl http://localhost:8000/health
curl http://localhost:8001/health
curl http://localhost:8002/health
```

## ✅ Summary

The system is now ready with:
- **Multiple API endpoints** exposed and documented
- **Counter successfully reset** for 300 records
- **Processing pipeline** ready to run
- **Comprehensive tooling** for management and testing

All 300 records from the `sentimental_analysis` collection can now be processed from the beginning using the periodic job service.
