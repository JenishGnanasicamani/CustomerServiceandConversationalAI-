# System Endpoints and Counter Reset Summary

## Overview
This document provides a comprehensive overview of all exposed endpoints in the Customer Conversation Performance Analysis system and the counter reset functionality.

## ğŸŒ Exposed API Endpoints

### 1. Reporting API Server
**Base URL:** `http://localhost:8000` (when running `python src/reporting_api.py`)

#### Endpoints:
- **GET** `/` - Root endpoint with API information
- **GET** `/health` - Health check endpoint
- **GET** `/api/conversations` - Get all analyzed conversations
- **GET** `/api/conversations/{conversation_id}` - Get specific conversation analysis
- **GET** `/api/metrics/summary` - Get performance metrics summary
- **GET** `/api/kpis` - Get KPI analysis results
- **GET** `/api/collections` - Get MongoDB collection information

### 2. LLM Agent API Server
**Base URL:** `http://localhost:8001` (when running `python src/llm_agent_api.py`)

#### Endpoints:
- **POST** `/analyze` - Analyze conversation performance using LLM
- **GET** `/health` - Health check endpoint
- **GET** `/collections` - Get available MongoDB collections

### 3. Enhanced API Server
**Base URL:** `http://localhost:8002` (when running `python src/enhanced_api.py`)

#### Endpoints:
- **POST** `/analyze-conversation` - Enhanced conversation analysis
- **GET** `/health` - Health check endpoint

## ğŸ“Š Data Collections in MongoDB

### Primary Database: `csai`

#### Source Collections (Input Data):
1. **`sentimental_analysis`** - 300 documents
   - Main collection for sentiment analysis data
   - Fields: `_id`, `conversation_number`, `customer`, `tweets`, `source_document_id`, `classification`, `processed_at`, `retry_count`

2. **`conversation_set`** - 300 documents
   - Conversation metadata and processing status
   - Fields: `_id`, `conversation_number`, `customer`, `tweets`, `last_processed_at`, `processing_attempts`, `status`

3. **`messages`** - 5,442 documents
   - Raw message data
   - Fields: `_id`, `conversation_number`, `tweets`

4. **`Testing_Vivek`** - 10,150 documents
   - Large test dataset
   - Fields: `_id`, `conversation_number`, `tweets`

5. **`Capstone Sample`** - 20 documents
   - Sample dataset for testing
   - Fields: `_id`, `conversation_number`, `tweets`

#### Output Collections:
1. **`agentic_analysis`** - 0 documents (target for processed results)
   - Stores performance analysis results
   - Generated by periodic job processing

2. **`job_state`** - 0 documents (processing tracker)
   - Tracks processing progress and checkpoints
   - Used for incremental processing

## ğŸ”„ Counter Reset Functionality

### Purpose
Reset the processing counter so that all records from source collections can be processed again by the periodic job service.

### Available Reset Scripts:

#### 1. Basic Reset Script
```bash
python reset_sentiment_analysis_counter.py
```
- Resets counter for default collection
- Includes backup functionality

#### 2. Advanced Reset Script (Recommended)
```bash
python reset_processing_counter_corrected.py
```

**Usage Options:**
```bash
# Reset for sentimental_analysis collection (default)
python reset_processing_counter_corrected.py

# Reset for specific collection
python reset_processing_counter_corrected.py --collection sentimental_analysis

# Reset without backup
python reset_processing_counter_corrected.py --no-backup

# Reset without confirmation prompt
python reset_processing_counter_corrected.py --no-confirm

# Reset for different database
python reset_processing_counter_corrected.py --db-name custom_db

# Reset with custom MongoDB connection
python reset_processing_counter_corrected.py --connection-string "mongodb://custom:27017/"
```

### Reset Process:
1. **Connect** to MongoDB database
2. **Analyze** current processing state
3. **Show** available collections and record counts
4. **Backup** current job state (optional)
5. **Reset** the job state counter
6. **Verify** reset was successful
7. **Display** impact summary

### Current Status (Post-Reset):
- âœ… **Counter successfully reset**
- ğŸ“Š **300 records** ready for processing in `sentimental_analysis`
- ğŸ¯ **Processing will start from the beginning**
- ğŸ”„ **No existing job state** - fresh start

## ğŸš€ Running the System

### 1. Start API Servers
```bash
# Terminal 1: Start Reporting API
python src/reporting_api.py

# Terminal 2: Start LLM Agent API  
python src/llm_agent_api.py

# Terminal 3: Start Enhanced API
python src/enhanced_api.py
```

### 2. Process Data
```bash
# Run periodic job to process all 300 records
python run_periodic_job.py
```

### 3. Test Endpoints
```bash
# Test reporting API
python test_reporting_api_with_actual_data.py

# Test direct MongoDB queries
python test_direct_mongodb_query.py
```

## ğŸ“ˆ Processing Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  sentimental_       â”‚â”€â”€â”€â–¶â”‚  Periodic Job       â”‚â”€â”€â”€â–¶â”‚  agentic_analysis   â”‚
â”‚  analysis           â”‚    â”‚  Service            â”‚    â”‚  (Results)          â”‚
â”‚  (300 records)      â”‚    â”‚                     â”‚    â”‚  (0 â†’ 300 records)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  job_state          â”‚
                           â”‚  (Progress Tracker) â”‚
                           â”‚  (Reset âœ…)         â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Configuration Files

### Key Configuration:
- `config/periodic_job_config.yaml` - Periodic job settings
- `config/agent_performance_config.yaml` - Performance analysis settings
- `config/aicore_credentials.yaml` - AI Core credentials

### Environment Variables:
- `MONGODB_CONNECTION_STRING` - MongoDB connection string
- `AICORE_*` - SAP AI Core credentials

## ğŸ“ Usage Examples

### Reset Counter and Process Data:
```bash
# 1. Reset the counter
python reset_processing_counter_corrected.py --collection sentimental_analysis

# 2. Run processing
python run_periodic_job.py

# 3. Check results via API
curl http://localhost:8000/api/conversations
```

### Check System Status:
```bash
# Check collections
python check_mongodb_collections.py

# Test API endpoints
curl http://localhost:8000/health
curl http://localhost:8001/health
curl http://localhost:8002/health
```

## âœ… Summary

The system is now ready with:
- **Multiple API endpoints** exposed and documented
- **Counter successfully reset** for 300 records
- **Processing pipeline** ready to run
- **Comprehensive tooling** for management and testing

All 300 records from the `sentimental_analysis` collection can now be processed from the beginning using the periodic job service.
