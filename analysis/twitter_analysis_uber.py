# -*- coding: utf-8 -*-
"""twitter_analysis_uber.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qX6D_JuUHaxYUghFT6OlaEvfT77-Yyof
"""

import pandas as pd

df = pd.read_csv('/content/Uber_Support_tweets.csv')
display(df.head())

df.shape

# Create a new 'role' column based on the 'inbound' column
df['role'] = df['inbound'].apply(lambda x: 'Customer' if x else 'Service Provider')

# Get the list of existing columns
cols = df.columns.tolist()

# Move the 'role' column to the second position (index 2)
cols.insert(2, cols.pop(cols.index('role')))

# Reindex the DataFrame with the new column order
df = df[cols]

# Display the head of the modified DataFrame
display(df.head())

# Convert 'created_at' to datetime objects
df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')

# Extract date and time into new columns
df['created_date'] = df['created_at'].dt.date
df['created_time'] = df['created_at'].dt.time

df=df.drop('created_at',axis=1)

# Get the list of existing columns
cols = df.columns.tolist()

# Remove 'created_at' if it exists
if 'created_at' in cols:
    cols.remove('created_at')

# Create a new list of columns with 'created_date' and 'created_time' at the desired position
# This approach ensures that 'created_date' and 'created_time' are inserted only once
new_cols = cols[:4] + ['created_date', 'created_time'] + cols[4:]

# Reindex the DataFrame with the new column order, dropping any duplicate columns in the process
df = df[new_cols].loc[:,~df[new_cols].columns.duplicated()]


# Display the head of the modified DataFrame
display(df.head())



from datetime import datetime

# Ensure 'created_date' is in datetime format
df['created_date'] = pd.to_datetime(df['created_date'], errors='coerce')

# Convert 'created_time' to datetime objects and then format as 24-hour time string
df['created_time'] = pd.to_datetime(df['created_time'], format='%I:%M:%S %p').dt.strftime('%H:%M:%S')

# Display the head of the DataFrame to show the modified 'created_time' column
display(df.head())

# Rename the column
df = df.rename(columns={'created_date': 'created_at'})

# Display the head of the DataFrame to show the renamed column
display(df.head())

"""# Task
Analyze the "Delta_Airline" file and build the conversations.

## Identify conversation starters

### Subtask:
Find the initial tweets that start a conversation (those with no `in_response_to_tweet_id`).

**Reasoning**:
Filter the dataframe to find tweets with no response, which signify the start of a conversation. Store the results in a new dataframe and display the head.
"""

conversation_starters_df = df[df['in_response_to_tweet_id'].isnull()]
display(conversation_starters_df.head())

conversation_starters_df.shape

"""## Trace conversations

### Subtask:
For the first few conversation starters, trace the subsequent tweets using `tweet_id`, `response_tweet_id`, and `in_response_to_tweet_id` to build complete conversation threads.

**Reasoning**:
Iterate through the all the conversation starters and trace their replies to build complete conversation threads.
"""

conversations = []
for index, starter_tweet in conversation_starters_df.iterrows():
    conversation = [starter_tweet]
    current_tweet_id = starter_tweet['tweet_id']

    while True:
        next_tweet = df[df['in_response_to_tweet_id'] == current_tweet_id]
        if not next_tweet.empty:
            # Assuming there's only one reply per tweet in a simple thread
            current_tweet = next_tweet.iloc[0]
            conversation.append(current_tweet)
            current_tweet_id = current_tweet['tweet_id']
        else:
            break
    conversations.append(conversation)

# Display the first conversation as an example
if conversations:
    print("First Conversation Thread:")
    for tweet in conversations[0]:
        display(tweet)



"""## Structure the conversations

### Subtask:
Organize the identified tweets into the distinct conversation structures.

**Reasoning**:
Create a list to store the structured conversations and iterate through the traced conversations to organize them into a structured format.
"""

import json
import numpy as np
from datetime import datetime, time # Import time as well
import pandas as pd # Import pandas

# Custom encoder to handle NumPy types, including booleans and datetime
class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.bool_):
            return bool(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        # Add handling for pandas Series to convert them to dictionary
        if isinstance(obj, pd.Series):
            return obj.to_dict()
        # Add handling for pandas Timestamp objects
        if isinstance(obj, pd.Timestamp):
            return obj.isoformat() # Convert Timestamp to ISO 8601 string
        # Add handling for datetime objects
        if isinstance(obj, datetime):
            return obj.isoformat() # Convert datetime to ISO 8601 string
        # Handle time objects
        if isinstance(obj, time): # Use the imported time object
            return obj.isoformat()
        return super(NpEncoder, self).default(obj)

structured_conversations = []

for i, conversation_thread in enumerate(conversations):  # Process all conversations
    structured_thread = {
        'conversation_number': i + 1,
        'customer': 'Uber',
        'tweets': []
    }
    for tweet in conversation_thread:
        structured_thread['tweets'].append({
            'tweet_id': tweet['tweet_id'],
            'author_id': tweet['author_id'],
            'role': tweet['role'],
            'inbound': tweet['inbound'],
            'created_at': tweet['created_at'],
            'created_time': tweet['created_time'], # Include created_time
            'text': tweet['text']
        })
    structured_conversations.append(structured_thread)

# Display the first structured conversation as an example
if structured_conversations:
    print("First Structured Conversation:")
    # Print the dictionary representation for clarity
    print(json.dumps(structured_conversations[0], indent=4, cls=NpEncoder))



!pip install pytz

import random
import json
import numpy as np
from datetime import datetime, time # Import time as well
import pytz
import pandas as pd # Import pandas

# Get current time in Indian Standard Time (IST)
ist = pytz.timezone('Asia/Kolkata')
current_time_ist = datetime.now(ist)

# Generate filename with current date and time (IST) in requested format
formatted_time = current_time_ist.strftime('%Y%m%d_%H%M%S')
output_filename = f'Uber_100_Oct2017_{formatted_time}.json'


# Custom encoder to handle NumPy types, including booleans and datetime
class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.bool_):
            return bool(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        # Add handling for pandas Series to convert them to dictionary
        if isinstance(obj, pd.Series):
            return obj.to_dict()
        # Add handling for datetime objects (including pandas Timestamp which is a subclass)
        if isinstance(obj, (datetime, pd.Timestamp)):
            return obj.isoformat() # Convert datetime/Timestamp to ISO 8601 string
        # Handle time objects
        if isinstance(obj, time): # Use the imported time object
            return obj.isoformat()
        return super(NpEncoder, self).default(obj)


# Filter conversations for October 2017
oct_2017_conversations = []
for conversation in structured_conversations:
    # Check if any tweet in the conversation is from Oct 2017
    if any(isinstance(tweet['created_at'], (datetime, pd.Timestamp)) and
           tweet['created_at'].year == 2017 and
           tweet['created_at'].month == 10
           for tweet in conversation['tweets']):
        oct_2017_conversations.append(conversation)


# Select 100 random conversations from the filtered list
if len(oct_2017_conversations) >= 100:
    random_oct_2017_conversations = random.sample(oct_2017_conversations, 100)
else:
    random_oct_2017_conversations = oct_2017_conversations
    print(f"Warning: Only {len(oct_2017_conversations)} conversations found for October 2017. Saving all of them.")


# Save the selected conversations to a JSON file
with open(output_filename, 'w') as f:
    json.dump(random_oct_2017_conversations, f, indent=4, cls=NpEncoder)

print(f"Selected {len(random_oct_2017_conversations)} random conversations from October 2017 saved to '{output_filename}'")