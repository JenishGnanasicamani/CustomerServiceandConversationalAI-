# -*- coding: utf-8 -*-
"""twitter_analysis_Delta.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N5vAm7TCO19impKYa3JirXi7uPHtFdDR
"""

import pandas as pd

!wget https://raw.githubusercontent.com/Vivek-Sajjan/Conversational-AI-Project/main/Dataset/Delta_Airline_tweets.csv

df = pd.read_csv('Delta_Airline_tweets.csv')
display(df.head())

df.shape

# Create a new 'role' column based on the 'inbound' column
df['role'] = df['inbound'].apply(lambda x: 'Customer' if x else 'Service Provider')

# Get the list of existing columns
cols = df.columns.tolist()

# Move the 'role' column to the second position (index 2)
cols.insert(2, cols.pop(cols.index('role')))

# Reindex the DataFrame with the new column order
df = df[cols]

# Display the head of the modified DataFrame
display(df.head())

# Get the list of existing columns
cols = df.columns.tolist()

# Remove the original 'created_date', and 'created_time' columns from the list
cols.remove('created_date')
cols.remove('created_time')

# Find the index where you want to insert the new columns (e.g., after 'role')
# Assuming 'role' is at index 2 after the previous modifications
insert_pos = cols.index('inbound')

# Insert the new columns into the desired position
cols.insert(insert_pos, 'created_date')
cols.insert(insert_pos + 1, 'created_time')

# Reindex the DataFrame with the new column order
df = df[cols]

# Display the head of the modified DataFrame
display(df.head())

from datetime import datetime

# Ensure 'created_date' is in datetime format
df['created_date'] = pd.to_datetime(df['created_date'], errors='coerce')

# Change the year to 2024
# Using errors='coerce' in to_datetime handles any potential parsing issues by turning them into NaT
df['created_date'] = df['created_date'].apply(lambda x: x.replace(year=2024) if pd.notnull(x) else None)

# Display the head of the DataFrame to show the updated 'created_date' column
display(df.head())

# Rename the column
df = df.rename(columns={'created_date': 'created_at'})

# Display the head of the DataFrame to show the renamed column
display(df.head())

"""# Task
Analyze the "Delta_Airline" file and build the conversations.

## Identify conversation starters

### Subtask:
Find the initial tweets that start a conversation (those with no `in_response_to_tweet_id`).

**Reasoning**:
Filter the dataframe to find tweets with no response, which signify the start of a conversation. Store the results in a new dataframe and display the head.
"""

conversation_starters_df = df[df['in_response_to_tweet_id'].isnull()]
display(conversation_starters_df.head())

conversation_starters_df.shape

"""## Trace conversations

### Subtask:
For the first few conversation starters, trace the subsequent tweets using `tweet_id`, `response_tweet_id`, and `in_response_to_tweet_id` to build complete conversation threads.

**Reasoning**:
Iterate through the all the conversation starters and trace their replies to build complete conversation threads.
"""

conversations = []
for index, starter_tweet in conversation_starters_df.iterrows():
    conversation = [starter_tweet]
    current_tweet_id = starter_tweet['tweet_id']

    while True:
        next_tweet = df[df['in_response_to_tweet_id'] == current_tweet_id]
        if not next_tweet.empty:
            # Assuming there's only one reply per tweet in a simple thread
            current_tweet = next_tweet.iloc[0]
            conversation.append(current_tweet)
            current_tweet_id = current_tweet['tweet_id']
        else:
            break
    conversations.append(conversation)

# Display the first conversation as an example
if conversations:
    print("First Conversation Thread:")
    for tweet in conversations[0]:
        display(tweet)



"""## Structure the conversations

### Subtask:
Organize the identified tweets into the distinct conversation structures.

**Reasoning**:
Create a list to store the structured conversations and iterate through the traced conversations to organize them into a structured format.
"""

import json
import numpy as np

# Custom encoder to handle NumPy types, including booleans
class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.bool_):
            return bool(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        # Add handling for pandas Series to convert them to dictionary
        if isinstance(obj, pd.Series):
            return obj.to_dict()
        return super(NpEncoder, self).default(obj)

structured_conversations = []

for i, conversation_thread in enumerate(conversations):  # Process all conversations
    structured_thread = {
        'conversation_number': i + 1,
        'customer': 'Delta',
        'tweets': []
    }
    for tweet in conversation_thread:
        structured_thread['tweets'].append({
            'tweet_id': tweet['tweet_id'],
            'author_id': tweet['author_id'],
            'role': tweet['role'],
            'inbound': tweet['inbound'],
            'created_at': tweet['created_at'],
            'text': tweet['text']
        })
    structured_conversations.append(structured_thread)

# Display the first structured conversation as an example
if structured_conversations:
    print("First Structured Conversation:")
    # Print the dictionary representation for clarity
    print(json.dumps(structured_conversations[0], indent=4, cls=NpEncoder))



!pip install pytz

import random
import json
import numpy as np
from datetime import datetime
import pytz

# Get current time in Indian Standard Time (IST)
ist = pytz.timezone('Asia/Kolkata')
current_time_ist = datetime.now(ist)

# Generate filename with current date and time (IST) in requested format
formatted_time = current_time_ist.strftime('%Y%m%d_%H%M%S')
output_filename = f'Delta_Airline_100_Dec2024_{formatted_time}.json'


# Custom encoder to handle NumPy types, including booleans and datetime
class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.bool_):
            return bool(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        # Add handling for pandas Series to convert them to dictionary
        if isinstance(obj, pd.Series):
            return obj.to_dict()
        # Add handling for datetime objects (including pandas Timestamp which is a subclass)
        if isinstance(obj, datetime):
            # Format as YYYY-MM-DD string
            return obj.strftime('%Y-%m-%d')
        # Handle time objects
        if isinstance(obj, datetime.time):
            return obj.isoformat()
        return super(NpEncoder, self).default(obj)


# Filter conversations for December 2024
dec_2024_conversations = []
for conversation in structured_conversations:
    # Check if any tweet in the conversation is from Dec 2024
    if any(isinstance(tweet['created_at'], datetime) and
           tweet['created_at'].year == 2024 and
           tweet['created_at'].month == 12
           for tweet in conversation['tweets']):
        dec_2024_conversations.append(conversation)


# Select 100 random conversations from the filtered list
if len(dec_2024_conversations) >= 100:
    random_dec_2024_conversations = random.sample(dec_2024_conversations, 100)
else:
    random_dec_2024_conversations = dec_2024_conversations
    print(f"Warning: Only {len(dec_2024_conversations)} conversations found for December 2024. Saving all of them.")


# Save the selected conversations to a JSON file
with open(output_filename, 'w') as f:
    json.dump(random_dec_2024_conversations, f, indent=4, cls=NpEncoder)

print(f"Selected {len(random_dec_2024_conversations)} random conversations from December 2024 saved to '{output_filename}'")